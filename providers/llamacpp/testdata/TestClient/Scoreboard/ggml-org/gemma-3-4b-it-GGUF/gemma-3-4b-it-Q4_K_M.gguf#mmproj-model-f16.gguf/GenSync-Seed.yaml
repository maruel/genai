---
version: 2
interactions:
- id: 0
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 128
    host: localhost
    body: "{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":\"Say hello. Use only one word.\"}]}],\"seed\":42,\"cache_prompt\":true}\n"
    headers:
      Content-Type:
      - application/json; charset=utf-8
    url: http://localhost/chat/completions
    method: POST
  response:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 547
    body: "{\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Hello.\"}}],\"created\":1756253423,\"model\":\"gpt-3.5-turbo\",\"system_fingerprint\":\"b6283-1d8d83de\",\"object\":\"chat.completion\",\"usage\":{\"completion_tokens\":3,\"prompt_tokens\":17,\"total_tokens\":20},\"id\":\"chatcmpl-BNDJdPr7hShh7Hyjhaw2oYvD5eNTPswN\",\"timings\":{\"prompt_n\":1,\"prompt_ms\":15.401,\"prompt_per_token_ms\":15.401,\"prompt_per_second\":64.9308486461918,\"predicted_n\":3,\"predicted_ms\":31.869,\"predicted_per_token_ms\":10.623,\"predicted_per_second\":94.13536665725313}}"
    headers:
      Access-Control-Allow-Origin:
      - ""
      Content-Length:
      - "547"
      Content-Type:
      - application/json; charset=utf-8
      Keep-Alive:
      - timeout=5, max=100
      Server:
      - llama.cpp
    status: 200 OK
    code: 200
    duration: 93ms
