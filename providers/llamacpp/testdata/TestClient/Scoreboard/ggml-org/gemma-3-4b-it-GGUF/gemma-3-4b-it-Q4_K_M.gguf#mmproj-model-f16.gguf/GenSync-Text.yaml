---
version: 2
interactions:
- id: 0
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 118
    host: localhost
    body: "{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":\"Say hello. Use only one word.\"}]}],\"cache_prompt\":true}\n"
    headers:
      Content-Type:
      - application/json; charset=utf-8
    url: http://localhost/chat/completions
    method: POST
  response:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 573
    body: "{\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Hello.\"}}],\"created\":1756253423,\"model\":\"gpt-3.5-turbo\",\"system_fingerprint\":\"b6283-1d8d83de\",\"object\":\"chat.completion\",\"usage\":{\"completion_tokens\":3,\"prompt_tokens\":17,\"total_tokens\":20},\"id\":\"chatcmpl-B5WWcZl77wKJFn66InZkDlRVYF8OxRkI\",\"timings\":{\"prompt_n\":17,\"prompt_ms\":64.062,\"prompt_per_token_ms\":3.7683529411764702,\"prompt_per_second\":265.3679248228279,\"predicted_n\":3,\"predicted_ms\":32.697,\"predicted_per_token_ms\":10.899000000000001,\"predicted_per_second\":91.75153683824203}}"
    headers:
      Access-Control-Allow-Origin:
      - ""
      Content-Length:
      - "573"
      Content-Type:
      - application/json; charset=utf-8
      Keep-Alive:
      - timeout=5, max=100
      Server:
      - llama.cpp
    status: 200 OK
    code: 200
    duration: 98ms
