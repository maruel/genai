---
version: 2
interactions:
- id: 0
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 202
    host: generativelanguage.googleapis.com
    body: "{\"contents\":[{\"role\":\"user\",\"parts\":[{\"text\":\"Say hello. Do not emit other words.\"}]}],\"generationConfig\":{\"responseModalities\":[\"TEXT\"],\"thinkingConfig\":{\"includeThoughts\":true,\"thinkingBudget\":512}}}\n"
    headers:
      Content-Type:
      - application/json; charset=utf-8
    url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite-preview-09-2025:generateContent
    method: POST
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: -1
    uncompressed: true
    body: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"**Precise Execution Required**\\n\\nOkay, here's the situation. The user's given me a remarkably concise instruction: \\\"Say hello. Do not emit other words.\\\" As a seasoned professional in this domain, it's immediately clear what I need to do.\\n\\nFirst, I've got to break down the request. \\\"Say hello\\\" – that's the *what*. \\\"Do not emit other words\\\" – that's the *how*. No room for interpretation here. This is straight-forward, and I am confident that I can answer correctly.\\n\\nNext, I need to define the perfect output. In this case, it's just the word \\\"hello\\\". Simple. I'm going to run a mental checklist. Does the output meet the constraints? Yes. Is there any ambiguity? Absolutely not. My confidence in generating the required response is a solid 5 out of 5.\\n\\nNow, it's just a matter of executing the command. Based on the constraints I've validated, the response will be exactly and only \\\"hello\\\". I'm ready to proceed.\\n\",\n            \"thought\": true\n          },\n          {\n            \"text\": \"Hello\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 10,\n    \"candidatesTokenCount\": 1,\n    \"totalTokenCount\": 133,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 10\n      }\n    ],\n    \"thoughtsTokenCount\": 122\n  },\n  \"modelVersion\": \"gemini-2.5-flash-lite-preview-09-2025\",\n  \"responseId\": \"wzNAacPUJYSf-8YPz8yAsQ8\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=2007
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-Xss-Protection:
      - "0"
    status: 200 OK
    code: 200
    duration: 2.018s
