---
version: 2
interactions:
    - id: 0
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 111
        transfer_encoding: []
        trailer: {}
        host: api.groq.com
        remote_addr: ""
        request_uri: ""
        body: |
            {"messages":[{"role":"user","content":"Say hello. Use only one word."}],"model":"qwen-qwq-32b","stream":false}
        form: {}
        headers:
            Content-Type:
                - application/json; charset=utf-8
        url: https://api.groq.com/openai/v1/chat/completions
        method: POST
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        transfer_encoding: []
        trailer: {}
        content_length: -1
        uncompressed: true
        body: |
            {"id":"chatcmpl-532de7bc-787d-42dc-b3be-1364dbb37a8c","object":"chat.completion","created":1748716153,"model":"qwen-qwq-32b","choices":[{"index":0,"message":{"role":"assistant","content":"\n\u003cthink\u003e\nOkay, the user wants me to say \"hello\" using only one word. Let me think... The obvious answer is \"Hello.\" But wait, maybe they want something different? Like a variation or another language? The instructions specify to use one word in English, right? The query doesn't mention another language, so probably just \"Hello\". But the user might be testing if I follow the one-word rule strictly. Let me check the requirements again: \"Say hello. Use only one word.\" So \"Hello\" is exactly one word and does the job. No need to overcomplicate. Maybe they want it lowercase? But the example responses usually capitalize, and it's more polite. Yeah, I should just go with \"Hello\".\n\nWait, maybe \"Hi\" is shorter? But the question says \"say hello\", so \"Hi\" is a greeting but not exactly \"hello\". The exact word requested is \"hello\", so the answer must be \"Hello\". No other options fit better. Alright, I think that's it. Just \"Hello\".\n\u003c/think\u003e\n\nHello."},"logprobs":null,"finish_reason":"stop"}],"usage":{"queue_time":0.066814544,"prompt_tokens":18,"prompt_time":0.003260003,"completion_tokens":218,"completion_time":0.542081635,"total_tokens":236,"total_time":0.545341638},"usage_breakdown":{"models":null},"system_fingerprint":"fp_1e88ca32eb","x_groq":{"id":"req_01jwksntcxfp384jge5nz72qww"}}
        headers:
            Alt-Svc:
                - h3=":443"; ma=86400
            Cache-Control:
                - private, max-age=0, no-store, no-cache, must-revalidate
            Cf-Cache-Status:
                - DYNAMIC
            Cf-Ray:
                - 948889159a40a2a0-YUL
            Content-Type:
                - application/json
            Server:
                - cloudflare
            Vary:
                - Origin
            X-Groq-Region:
                - us-central-1
            X-Ratelimit-Limit-Requests:
                - "500000"
            X-Ratelimit-Limit-Tokens:
                - "250000"
            X-Ratelimit-Remaining-Requests:
                - "499999"
            X-Ratelimit-Remaining-Tokens:
                - "249988"
            X-Ratelimit-Reset-Requests:
                - 172.799999ms
            X-Ratelimit-Reset-Tokens:
                - 2.879999ms
            X-Request-Id:
                - req_01jwksntcxfp384jge5nz72qww
        status: 200 OK
        code: 200
        duration: 671ms
