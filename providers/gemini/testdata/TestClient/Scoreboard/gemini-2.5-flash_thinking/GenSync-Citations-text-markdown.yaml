---
version: 2
interactions:
- id: 0
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 307
    host: generativelanguage.googleapis.com
    body: "{\"contents\":[{\"role\":\"user\",\"parts\":[{\"text\":\"# Quackiland\\n\\nThe capital of Quackiland is Quack. The Big Canard Statue is located in Quack.\"},{\"text\":\"What is the capital of Quackiland?\"}]}],\"generationConfig\":{\"responseModalities\":[\"TEXT\"],\"thinkingConfig\":{\"includeThoughts\":true,\"thinkingBudget\":512}}}\n"
    headers:
      Content-Type:
      - application/json; charset=utf-8
    url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent
    method: POST
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: -1
    uncompressed: true
    body: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"**My Analytical Breakdown of the User's Query**\\n\\nAlright, let's break this down. First, the user has presented a concise piece of text, seemingly describing some made-up place called \\\"Quackiland,\\\" and has followed that with a straightforward question: \\\"What is the capital of Quackiland?\\\"  It's a simple, direct request.\\n\\nMy next step is to quickly scan the text.  I'm looking for key terms, anything related to \\\"capital,\\\" the name \\\"Quackiland,\\\" and the verb \\\"is,\\\" to pinpoint the relevant information.\\n\\nAha!  The very first sentence, \\\"The capital of Quackiland is Quack,\\\"  already gives me the answer. No need to dig any deeper.\\n\\nThe response then is simple and direct.  Based on the provided information, the answer to \\\"What is the capital of Quackiland?\\\" is, unequivocally, \\\"Quack.\\\"  Case closed.\\n\",\n            \"thought\": true\n          },\n          {\n            \"text\": \"The capital of Quackiland is **Quack**.\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 36,\n    \"candidatesTokenCount\": 11,\n    \"totalTokenCount\": 167,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 36\n      }\n    ],\n    \"thoughtsTokenCount\": 120\n  },\n  \"modelVersion\": \"gemini-2.5-flash\",\n  \"responseId\": \"eviyaMrzJPqu_uMPu5uf6A0\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=2306
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-Xss-Protection:
      - "0"
    status: 200 OK
    code: 200
    duration: 2.313s
