---
version: 2
interactions:
- id: 0
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 130
    host: api.together.xyz
    body: "{\"model\":\"meta-llama/Llama-3.2-1B-Instruct\",\"stream\":true,\"messages\":[{\"role\":\"user\",\"content\":\"Say hello. Use only one word.\"}]}\n"
    headers:
      Content-Type:
      - application/json; charset=utf-8
    url: https://api.together.xyz/v1/chat/completions
    method: POST
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: 380
    body: "{\n  \"id\": \"oPBXga7-2kFHot-9ade0a294f38a275\",\n  \"error\": {\n    \"message\": \"Unable to access non-serverless model meta-llama/Llama-3.2-1B-Instruct. Please visit https://api.together.ai/models/meta-llama/Llama-3.2-1B-Instruct to create and start a new dedicated endpoint for the model.\",\n    \"type\": \"invalid_request_error\",\n    \"param\": null,\n    \"code\": \"model_not_available\"\n  }\n}"
    headers:
      Access-Control-Allow-Origin:
      - "*"
      Alt-Svc:
      - h3=":443"; ma=86400
      Cf-Cache-Status:
      - DYNAMIC
      Cf-Ray:
      - 9ade0a294f38a275-YUL
      Content-Length:
      - "380"
      Content-Type:
      - application/json; charset=utf-8
      Etag:
      - W/"17c-fPgYpbP5rOwl/41Ny69vJNOj8rY"
      Retry-After:
      - "2"
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=15552000; includeSubDomains
      Vary:
      - Accept-Encoding
      X-Api-Received:
      - "2025-12-14T13:27:37.356Z"
      X-Content-Type-Options:
      - nosniff
      X-Ratelimit:
      - "false"
      X-Ratelimit-Limit:
      - "10"
      X-Ratelimit-Limit-Tokens:
      - "3000"
      X-Ratelimit-Remaining:
      - "19"
      X-Ratelimit-Remaining-Tokens:
      - "3000"
      X-Ratelimit-Reset:
      - "2"
    status: 400 Bad Request
    code: 400
    duration: 257ms
