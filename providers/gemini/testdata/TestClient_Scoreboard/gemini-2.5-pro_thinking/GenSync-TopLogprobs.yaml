---
version: 2
interactions:
    - id: 0
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 233
        host: generativelanguage.googleapis.com
        body: |
            {"contents":[{"role":"user","parts":[{"text":"Say hello. Use only one word."}]}],"generationConfig":{"responseModalities":["TEXT"],"responseLogprobs":true,"logprobs":2,"thinkingConfig":{"includeThoughts":true,"thinkingBudget":512}}}
        headers:
            Content-Type:
                - application/json; charset=utf-8
        url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent
        method: POST
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        content_length: -1
        uncompressed: true
        body: |
            {
              "candidates": [
                {
                  "content": {
                    "parts": [
                      {
                        "text": "**My Processing of a Simple Greeting**\n\nOkay, so the user wants me to \"Say hello\" but with a single word. Simple enough, but the constraint makes it interesting. My first step, as always, is to dissect the prompt. The core requirement is clear: a greeting. The constraint is equally clear: just one word.\n\nNext, I need to brainstorm. Let's see... \"Hello,\" \"Hi,\" \"Hey,\" \"Greetings,\" \"Howdy,\" \"Yo,\" \"Aloha,\" \"Ciao.\"  A good list of possibilities. Now, I have to evaluate each one against the prompt's requirements.\n\n\"Hello\" works directly. It *is* a greeting, and it's just one word. \"Hi\" is similar, a bit more informal. \"Hey\" is even more informal. \"Greetings\" is a bit formal, possibly a little archaic. \"Howdy\" is regional, but still technically fits. \"Yo\" is extremely informal. \"Aloha\" is specific to Hawaiian culture, and \"Ciao\" is Italian.\n\nNow, which one is the *best* fit? Well, the prompt *literally* says \"Say hello.\" The most direct, unambiguous response to that is, well, \"Hello.\" It's neutral, universally understood, and exactly what the user asked for, in a word. It's the perfect solution given the constraints.\n",
                        "thought": true
                      },
                      {
                        "text": "Hello"
                      }
                    ],
                    "role": "model"
                  },
                  "finishReason": "STOP",
                  "index": 0,
                  "logprobsResult": {
                    "topCandidates": [
                      {
                        "candidates": [
                          {
                            "token": "Hello",
                            "logProbability": -0.00012956835,
                            "tokenId": 9259
                          },
                          {
                            "token": "How",
                            "logProbability": -9.301575,
                            "tokenId": 3910
                          }
                        ]
                      }
                    ],
                    "chosenCandidates": [
                      {
                        "token": "Hello",
                        "logProbability": -0.00012956835,
                        "tokenId": 9259
                      }
                    ]
                  }
                }
              ],
              "usageMetadata": {
                "promptTokenCount": 9,
                "candidatesTokenCount": 1,
                "totalTokenCount": 381,
                "promptTokensDetails": [
                  {
                    "modality": "TEXT",
                    "tokenCount": 9
                  }
                ],
                "thoughtsTokenCount": 371
              },
              "modelVersion": "gemini-2.5-pro",
              "responseId": "edOXaLDDGLPV1MkPkZTGwQs"
            }
        headers:
            Alt-Svc:
                - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
            Content-Type:
                - application/json; charset=UTF-8
            Server:
                - scaffolding on HTTPServer2
            Server-Timing:
                - gfet4t7; dur=5994
            Vary:
                - Origin
                - X-Origin
                - Referer
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - SAMEORIGIN
            X-Xss-Protection:
                - "0"
        status: 200 OK
        code: 200
        duration: 6.007s
