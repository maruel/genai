---
version: 2
interactions:
- id: 0
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 202
    host: generativelanguage.googleapis.com
    body: "{\"contents\":[{\"role\":\"user\",\"parts\":[{\"text\":\"Say hello. Do not emit other words.\"}]}],\"generationConfig\":{\"responseModalities\":[\"TEXT\"],\"thinkingConfig\":{\"includeThoughts\":true,\"thinkingBudget\":512}}}\n"
    headers:
      Content-Type:
      - application/json; charset=utf-8
    url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-05-06:generateContent
    method: POST
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: -1
    uncompressed: true
    body: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"**My Logical Path to a \\\"Hello\\\"**\\n\\nOkay, I understand. The user wants me to respond with the word \\\"hello.\\\" That's the core request. But there's a crucial constraint here: I'm *only* allowed to say \\\"hello.\\\" No other words, no embellishments. This is a very strict rule.\\n\\nSo, I need to craft a response that satisfies *only* that condition. The obvious answer is the word \\\"hello.\\\" But I need to be absolutely sure. Let's run a quick check. Does \\\"hello\\\" actually say \\\"hello\\\"? Yes. Does it contain anything else? No. Does it need any punctuation? The prompt doesn't forbid it, but to adhere to the strictest interpretation, let's keep it clean. Minimal is best. Therefore, the response is simply: \\\"hello\\\". It's the most direct and constraint-abiding answer.\\n\",\n            \"thought\": true\n          },\n          {\n            \"text\": \"Hello\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 10,\n    \"candidatesTokenCount\": 1,\n    \"totalTokenCount\": 198,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 10\n      }\n    ],\n    \"thoughtsTokenCount\": 187\n  },\n  \"modelVersion\": \"models/gemini-2.5-pro\",\n  \"responseId\": \"DPKxaOjqJqml1MkPosXumAo\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=4878
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-Xss-Protection:
      - "0"
    status: 200 OK
    code: 200
    duration: 4.888s
