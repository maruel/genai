---
version: 2
interactions:
    - id: 0
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 73
        transfer_encoding: []
        trailer: {}
        host: localhost
        remote_addr: ""
        request_uri: ""
        body: |
            {"messages":[{"role":"user","content":"Say hello. Use only one word."}]}
        form: {}
        headers:
            Content-Type:
                - application/json; charset=utf-8
        url: http://localhost/apply-template
        method: POST
      response:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        transfer_encoding: []
        trailer: {}
        content_length: 95
        uncompressed: false
        body: '{"prompt":"<|im_start|>user\nSay hello. Use only one word.<|im_end|>\n<|im_start|>assistant\n"}'
        headers:
            Access-Control-Allow-Origin:
                - ""
            Content-Length:
                - "95"
            Content-Type:
                - application/json; charset=utf-8
            Keep-Alive:
                - timeout=5, max=100
            Server:
                - llama.cpp
        status: 200 OK
        code: 200
        duration: 3ms
    - id: 1
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 174
        transfer_encoding: []
        trailer: {}
        host: localhost
        remote_addr: ""
        request_uri: ""
        body: |
            {"prompt":"<|im_start|>user\nSay hello. Use only one word.<|im_end|>\n<|im_start|>assistant\n","temperature":0.01,"n_predict":50,"stream":false,"seed":1,"cache_prompt":true}
        form: {}
        headers:
            Content-Type:
                - application/json; charset=utf-8
        url: http://localhost/completion
        method: POST
      response:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        transfer_encoding: []
        trailer: {}
        content_length: 1572
        uncompressed: false
        body: '{"index":0,"content":"Hello.","tokens":[],"id_slot":0,"stop":true,"model":"gpt-3.5-turbo","tokens_predicted":3,"tokens_evaluated":16,"generation_settings":{"n_predict":50,"seed":1,"temperature":0.009999999776482582,"dynatemp_range":0.0,"dynatemp_exponent":1.0,"top_k":40,"top_p":0.949999988079071,"min_p":0.05000000074505806,"xtc_probability":0.0,"xtc_threshold":0.10000000149011612,"typical_p":1.0,"repeat_last_n":64,"repeat_penalty":1.0,"presence_penalty":0.0,"frequency_penalty":0.0,"dry_multiplier":0.0,"dry_base":1.75,"dry_allowed_length":2,"dry_penalty_last_n":4096,"dry_sequence_breakers":["\n",":","\"","*"],"mirostat":0,"mirostat_tau":5.0,"mirostat_eta":0.10000000149011612,"stop":[],"max_tokens":50,"n_keep":0,"n_discard":0,"ignore_eos":false,"stream":false,"logit_bias":[],"n_probs":0,"min_keep":0,"grammar":"","grammar_lazy":false,"grammar_triggers":[],"preserved_tokens":[],"chat_format":"Content-only","samplers":["penalties","dry","top_k","typ_p","top_p","min_p","xtc","temperature"],"speculative.n_max":16,"speculative.n_min":0,"speculative.p_min":0.75,"timings_per_token":false,"post_sampling_probs":false,"lora":[]},"prompt":"<|im_start|>user\nSay hello. Use only one word.<|im_end|>\n<|im_start|>assistant\n","has_new_line":false,"truncated":false,"stop_type":"eos","stopping_word":"","tokens_cached":18,"timings":{"prompt_n":16,"prompt_ms":17548.593,"prompt_per_token_ms":1096.7870625,"prompt_per_second":0.9117540078569262,"predicted_n":3,"predicted_ms":14872.808,"predicted_per_token_ms":4957.602666666667,"predicted_per_second":0.20171039658415543}}'
        headers:
            Access-Control-Allow-Origin:
                - ""
            Content-Length:
                - "1572"
            Content-Type:
                - application/json; charset=utf-8
            Keep-Alive:
                - timeout=5, max=100
            Server:
                - llama.cpp
        status: 200 OK
        code: 200
        duration: 32.426s
    - id: 2
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 172
        transfer_encoding: []
        trailer: {}
        host: localhost
        remote_addr: ""
        request_uri: ""
        body: |
            {"messages":[{"role":"user","content":"Say hello. Use only one word."},{"role":"assistant","content":"Hello."},{"role":"user","content":"Say banana. Use only one word."}]}
        form: {}
        headers:
            Content-Type:
                - application/json; charset=utf-8
        url: http://localhost/apply-template
        method: POST
      response:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        transfer_encoding: []
        trailer: {}
        content_length: 196
        uncompressed: false
        body: '{"prompt":"<|im_start|>user\nSay hello. Use only one word.<|im_end|>\n<|im_start|>assistant\nHello.<|im_end|>\n<|im_start|>user\nSay banana. Use only one word.<|im_end|>\n<|im_start|>assistant\n"}'
        headers:
            Access-Control-Allow-Origin:
                - ""
            Content-Length:
                - "196"
            Content-Type:
                - application/json; charset=utf-8
            Keep-Alive:
                - timeout=5, max=100
            Server:
                - llama.cpp
        status: 200 OK
        code: 200
        duration: 3ms
    - id: 3
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 275
        transfer_encoding: []
        trailer: {}
        host: localhost
        remote_addr: ""
        request_uri: ""
        body: |
            {"prompt":"<|im_start|>user\nSay hello. Use only one word.<|im_end|>\n<|im_start|>assistant\nHello.<|im_end|>\n<|im_start|>user\nSay banana. Use only one word.<|im_end|>\n<|im_start|>assistant\n","temperature":0.01,"n_predict":50,"stream":false,"seed":1,"cache_prompt":true}
        form: {}
        headers:
            Content-Type:
                - application/json; charset=utf-8
        url: http://localhost/completion
        method: POST
      response:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        transfer_encoding: []
        trailer: {}
        content_length: 1671
        uncompressed: false
        body: '{"index":0,"content":"Banana.","tokens":[],"id_slot":0,"stop":true,"model":"gpt-3.5-turbo","tokens_predicted":4,"tokens_evaluated":36,"generation_settings":{"n_predict":50,"seed":1,"temperature":0.009999999776482582,"dynatemp_range":0.0,"dynatemp_exponent":1.0,"top_k":40,"top_p":0.949999988079071,"min_p":0.05000000074505806,"xtc_probability":0.0,"xtc_threshold":0.10000000149011612,"typical_p":1.0,"repeat_last_n":64,"repeat_penalty":1.0,"presence_penalty":0.0,"frequency_penalty":0.0,"dry_multiplier":0.0,"dry_base":1.75,"dry_allowed_length":2,"dry_penalty_last_n":4096,"dry_sequence_breakers":["\n",":","\"","*"],"mirostat":0,"mirostat_tau":5.0,"mirostat_eta":0.10000000149011612,"stop":[],"max_tokens":50,"n_keep":0,"n_discard":0,"ignore_eos":false,"stream":false,"logit_bias":[],"n_probs":0,"min_keep":0,"grammar":"","grammar_lazy":false,"grammar_triggers":[],"preserved_tokens":[],"chat_format":"Content-only","samplers":["penalties","dry","top_k","typ_p","top_p","min_p","xtc","temperature"],"speculative.n_max":16,"speculative.n_min":0,"speculative.p_min":0.75,"timings_per_token":false,"post_sampling_probs":false,"lora":[]},"prompt":"<|im_start|>user\nSay hello. Use only one word.<|im_end|>\n<|im_start|>assistant\nHello.<|im_end|>\n<|im_start|>user\nSay banana. Use only one word.<|im_end|>\n<|im_start|>assistant\n","has_new_line":false,"truncated":false,"stop_type":"eos","stopping_word":"","tokens_cached":39,"timings":{"prompt_n":18,"prompt_ms":11605.918,"prompt_per_token_ms":644.7732222222222,"prompt_per_second":1.5509328947524876,"predicted_n":4,"predicted_ms":13738.875,"predicted_per_token_ms":3434.71875,"predicted_per_second":0.2911446534013884}}'
        headers:
            Access-Control-Allow-Origin:
                - ""
            Content-Length:
                - "1671"
            Content-Type:
                - application/json; charset=utf-8
            Keep-Alive:
                - timeout=5, max=100
            Server:
                - llama.cpp
        status: 200 OK
        code: 200
        duration: 25.348s
