---
version: 2
interactions:
    - id: 0
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 256
        host: localhost
        body: |
            {"messages":[{"role":"user","content":[{"type":"text","text":"Is a banana a fruit? Do not include an explanation. Reply ONLY as JSON according to the provided schema: {\"is_fruit\": bool}."}]}],"response_format":{"type":"json_object"},"cache_prompt":true}
        headers:
            Content-Type:
                - application/json; charset=utf-8
        url: http://localhost/chat/completions
        method: POST
      response:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 578
        body: '{"choices":[{"finish_reason":"stop","index":0,"message":{"role":"assistant","content":"{\"is_fruit\": true}\n"}}],"created":1754859876,"model":"gpt-3.5-turbo","system_fingerprint":"b5994-c7f3169c","object":"chat.completion","usage":{"completion_tokens":9,"prompt_tokens":38,"total_tokens":47},"id":"chatcmpl-iQNnxPQVb6BO6UBwTZbclXPfBBBOZbGI","timings":{"prompt_n":1,"prompt_ms":67.287,"prompt_per_token_ms":67.287,"prompt_per_second":14.861711771961893,"predicted_n":9,"predicted_ms":398.338,"predicted_per_token_ms":44.25977777777778,"predicted_per_second":22.593877561267064}}'
        headers:
            Access-Control-Allow-Origin:
                - ""
            Content-Length:
                - "578"
            Content-Type:
                - application/json; charset=utf-8
            Keep-Alive:
                - timeout=5, max=100
            Server:
                - llama.cpp
        status: 200 OK
        code: 200
        duration: 1.119s
