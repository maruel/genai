The response object
background
boolean or null

Whether to run the model response in the background. Learn more.

created_at
number

Unix timestamp (in seconds) of when this Response was created.

error
object or null

An error object returned when the model fails to generate a Response.


Hide properties
code
string

The error code for the response.

message
string

A human-readable description of the error.

id
string

Unique identifier for this Response.

incomplete_details
object or null

Details about why the response is incomplete.


Hide properties
reason
string

The reason why the response is incomplete.

instructions
string or null

Inserts a system (or developer) message as the first item in the model's context.

When using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

max_output_tokens
integer or null

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

model
string

Model ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.

object
string

The object type of this resource - always set to response.

output
array

An array of content items generated by the model.

The length and order of items in the output array is dependent on the model's response.
Rather than accessing the first item in the output array and assuming it's an assistant message with the content generated by the model, you might consider using the output_text property where supported in SDKs.

Hide possible types
Output message
object
An output message from the model.


Hide properties
content
array

The content of the output message.


Show possible types
id
string

The unique ID of the output message.

role
string

The role of the output message. Always assistant.

status
string

The status of the message input. One of in_progress, completed, or incomplete. Populated when input items are returned via API.

type
string

The type of the output message. Always message.

File search tool call
object
The results of a file search tool call. See the file search guide for more information.


Hide properties
id
string

The unique ID of the file search tool call.

queries
array

The queries used to search for files.

status
string

The status of the file search tool call. One of in_progress, searching, incomplete or failed,

type
string

The type of the file search tool call. Always file_search_call.

results
array or null

The results of the file search tool call.


Show properties
Function tool call
object
A tool call to run a function. See the function calling guide for more information.


Hide properties
arguments
string

A JSON string of the arguments to pass to the function.

call_id
string

The unique ID of the function tool call generated by the model.

name
string

The name of the function to run.

type
string

The type of the function tool call. Always function_call.

id
string

The unique ID of the function tool call.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Web search tool call
object
The results of a web search tool call. See the web search guide for more information.


Hide properties
id
string

The unique ID of the web search tool call.

status
string

The status of the web search tool call.

type
string

The type of the web search tool call. Always web_search_call.

Computer tool call
object
A tool call to a computer use tool. See the computer use guide for more information.


Hide properties
action
object


Show possible types
call_id
string

An identifier used when responding to the tool call with output.

id
string

The unique ID of the computer call.

pending_safety_checks
array

The pending safety checks for the computer call.


Show properties
status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

type
string

The type of the computer call. Always computer_call.

Reasoning
object
A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your input to the Responses API for subsequent turns of a conversation if you are manually managing context.


Hide properties
id
string

The unique identifier of the reasoning content.

summary
array

Reasoning text contents.


Show properties
type
string

The type of the object. Always reasoning.

encrypted_content
string or null

The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Image generation call
object
An image generation request made by the model.


Hide properties
id
string

The unique ID of the image generation call.

result
string or null

The generated image encoded in base64.

status
string

The status of the image generation call.

type
string

The type of the image generation call. Always image_generation_call.

Code interpreter tool call
object
A tool call to run code.


Hide properties
code
string

The code to run.

id
string

The unique ID of the code interpreter tool call.

results
array

The results of the code interpreter tool call.


Show possible types
status
string

The status of the code interpreter tool call.

type
string

The type of the code interpreter tool call. Always code_interpreter_call.

container_id
string

The ID of the container used to run the code.

Local shell call
object
A tool call to run a command on the local shell.


Hide properties
action
object

Execute a shell command on the server.


Show properties
call_id
string

The unique ID of the local shell tool call generated by the model.

id
string

The unique ID of the local shell call.

status
string

The status of the local shell call.

type
string

The type of the local shell call. Always local_shell_call.

MCP tool call
object
An invocation of a tool on an MCP server.


Hide properties
arguments
string

A JSON string of the arguments passed to the tool.

id
string

The unique ID of the tool call.

name
string

The name of the tool that was run.

server_label
string

The label of the MCP server running the tool.

type
string

The type of the item. Always mcp_call.

error
string or null

The error from the tool call, if any.

output
string or null

The output from the tool call.

MCP list tools
object
A list of tools available on an MCP server.


Hide properties
id
string

The unique ID of the list.

server_label
string

The label of the MCP server.

tools
array

The tools available on the server.


Show properties
type
string

The type of the item. Always mcp_list_tools.

error
string or null

Error message if the server could not list tools.

MCP approval request
object
A request for human approval of a tool invocation.


Hide properties
arguments
string

A JSON string of arguments for the tool.

id
string

The unique ID of the approval request.

name
string

The name of the tool to run.

server_label
string

The label of the MCP server making the request.

type
string

The type of the item. Always mcp_approval_request.

output_text
string or null

SDK Only
SDK-only convenience property that contains the aggregated text output from all output_text items in the output array, if any are present. Supported in the Python and JavaScript SDKs.

parallel_tool_calls
boolean

Whether to allow the model to run tool calls in parallel.

previous_response_id
string or null

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about conversation state.

reasoning
object or null

o-series models only

Configuration options for reasoning models.


Hide properties
effort
string or null

o-series models only

Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

generate_summary
Deprecated
string or null

Deprecated: use summary instead.

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

summary
string or null

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

service_tier
string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.
When not set, the default behavior is 'auto'.
When this parameter is set, the response body will include the service_tier utilized.

status
string

The status of the response generation. One of completed, failed, in_progress, cancelled, queued, or incomplete.

temperature
number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.

text
object

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

Text inputs and outputs
Structured Outputs

Hide properties
format
object

An object specifying the format that the model must output.

Configuring { "type": "json_schema" } enables Structured Outputs, which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

The default format is { "type": "text" } with no additional options.

Not recommended for gpt-4o and newer models:

Setting to { "type": "json_object" } enables the older JSON mode, which ensures the message the model generates is valid JSON. Using json_schema is preferred for models that support it.


Hide possible types
Text
object
Default response format. Used to generate text responses.


Hide properties
type
string

The type of response format being defined. Always text.

JSON schema
object
JSON Schema response format. Used to generate structured JSON responses. Learn more about Structured Outputs.


Hide properties
name
string

The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.

schema
object

The schema for the response format, described as a JSON Schema object. Learn how to build JSON schemas here.

type
string

The type of response format being defined. Always json_schema.

description
string

A description of what the response format is for, used by the model to determine how to respond in the format.

strict
boolean or null

Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true. To learn more, read the Structured Outputs guide.

JSON object
object
JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.


Hide properties
type
string

The type of response format being defined. Always json_object.

tool_choice
string or object

How the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how to specify which tools the model can call.


Hide possible types
Tool choice mode
string
Controls which (if any) tool is called by the model.

none means the model will not call any tool and instead generates a message.

auto means the model can pick between generating a message or calling one or more tools.

required means the model must call one or more tools.

Hosted tool
object
Indicates that the model should use a built-in tool to generate a response. Learn more about built-in tools.


Hide properties
type
string

The type of hosted tool the model should to use. Learn more about built-in tools.

Allowed values are:

file_search
web_search_preview
computer_use_preview
code_interpreter
mcp
image_generation
Function tool
object
Use this option to force the model to call a specific function.


Hide properties
name
string

The name of the function to call.

type
string

For function calling, the type is always function.

tools
array

An array of tools the model may call while generating a response. You can specify which tool to use by setting the tool_choice parameter.

The two categories of tools you can provide the model are:

Built-in tools: Tools that are provided by OpenAI that extend the model's capabilities, like web search or file search. Learn more about built-in tools.
Function calls (custom tools): Functions that are defined by you, enabling the model to call your own code. Learn more about function calling.

Hide possible types
Function
object
Defines a function in your own code the model can choose to call. Learn more about function calling.


Hide properties
name
string

The name of the function to call.

parameters
object

A JSON schema object describing the parameters of the function.

strict
boolean

Whether to enforce strict parameter validation. Default true.

type
string

The type of the function tool. Always function.

description
string

A description of the function. Used by the model to determine whether or not to call the function.

File search
object
A tool that searches for relevant content from uploaded files. Learn more about the file search tool.


Hide properties
type
string

The type of the file search tool. Always file_search.

vector_store_ids
array

The IDs of the vector stores to search.

filters
object

A filter to apply.


Show possible types
max_num_results
integer

The maximum number of results to return. This number should be between 1 and 50 inclusive.

ranking_options
object

Ranking options for search.


Show properties
Web search preview
object
This tool searches the web for relevant results to use in a response. Learn more about the web search tool.


Hide properties
type
string

The type of the web search tool. One of web_search_preview or web_search_preview_2025_03_11.

search_context_size
string

High level guidance for the amount of context window space to use for the search. One of low, medium, or high. medium is the default.

user_location
object

The user's location.


Show properties
Computer use preview
object
A tool that controls a virtual computer. Learn more about the computer tool.


Hide properties
display_height
integer

The height of the computer display.

display_width
integer

The width of the computer display.

environment
string

The type of computer environment to control.

type
string

The type of the computer use tool. Always computer_use_preview.

MCP tool
object
Give the model access to additional tools via remote Model Context Protocol (MCP) servers. Learn more about MCP.


Hide properties
server_label
string

A label for this MCP server, used to identify it in tool calls.

server_url
string

The URL for the MCP server.

type
string

The type of the MCP tool. Always mcp.

allowed_tools
array or object

List of allowed tool names or a filter object.


Show possible types
headers
object or null

Optional HTTP headers to send to the MCP server. Use for authentication or other purposes.

require_approval
object or string

Specify which of the MCP server's tools require approval.


Show possible types
Code interpreter
object
A tool that runs Python code to help generate a response to a prompt.


Hide properties
container
string or object

The code interpreter container. Can be a container ID or an object that specifies uploaded file IDs to make available to your code.


Show possible types
type
string

The type of the code interpreter tool. Always code_interpreter.

Image generation tool
object
A tool that generates images using a model like gpt-image-1.


Hide properties
type
string

The type of the image generation tool. Always image_generation.

background
string

Background type for the generated image. One of transparent, opaque, or auto. Default: auto.

input_image_mask
object

Optional mask for inpainting. Contains image_url (string, optional) and file_id (string, optional).


Show properties
model
string

The image generation model to use. Default: gpt-image-1.

moderation
string

Moderation level for the generated image. Default: auto.

output_compression
integer

Compression level for the output image. Default: 100.

output_format
string

The output format of the generated image. One of png, webp, or jpeg. Default: png.

partial_images
integer

Number of partial images to generate in streaming mode, from 0 (default value) to 3.

quality
string

The quality of the generated image. One of low, medium, high, or auto. Default: auto.

size
string

The size of the generated image. One of 1024x1024, 1024x1536, 1536x1024, or auto. Default: auto.

Local shell tool
object
A tool that allows the model to execute shell commands in a local environment.


Hide properties
type
string

The type of the local shell tool. Always local_shell.

top_p
number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

truncation
string or null

The truncation strategy to use for the model response.

auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
disabled (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.
usage
object

Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.


Hide properties
input_tokens
integer

The number of input tokens.

input_tokens_details
object

A detailed breakdown of the input tokens.


Hide properties
cached_tokens
integer

The number of tokens that were retrieved from the cache. More on prompt caching.

output_tokens
integer

The number of output tokens.

output_tokens_details
object

A detailed breakdown of the output tokens.


Hide properties
reasoning_tokens
integer

The number of reasoning tokens.

total_tokens
integer

The total number of tokens used.

user
string

A stable identifier for your end-users. Used to boost cache hit rates by better bucketing similar requests and to help OpenAI detect and prevent abuse. Learn more.
