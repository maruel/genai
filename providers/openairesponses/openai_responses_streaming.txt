Streaming
When you create a Response with stream set to true, the server will emit server-sent events to the client as the Response is generated. This section contains the events that are emitted by the server.

Learn more about streaming responses.

response.created
An event that is emitted when a response is created.

response
object

The response that was created.


Hide properties
created_at
number

Unix timestamp (in seconds) of when this Response was created.

error
object or null

An error object returned when the model fails to generate a Response.


Hide properties
code
string

The error code for the response.

message
string

A human-readable description of the error.

id
string

Unique identifier for this Response.

incomplete_details
object or null

Details about why the response is incomplete.


Hide properties
reason
string

The reason why the response is incomplete.

instructions
string or null

Inserts a system (or developer) message as the first item in the model's context.

When using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

model
string

Model ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.

object
string

The object type of this resource - always set to response.

output
array

An array of content items generated by the model.

The length and order of items in the output array is dependent on the model's response.
Rather than accessing the first item in the output array and assuming it's an assistant message with the content generated by the model, you might consider using the output_text property where supported in SDKs.

Hide possible types
Output message
object
An output message from the model.


Hide properties
content
array

The content of the output message.


Show possible types
id
string

The unique ID of the output message.

role
string

The role of the output message. Always assistant.

status
string

The status of the message input. One of in_progress, completed, or incomplete. Populated when input items are returned via API.

type
string

The type of the output message. Always message.

File search tool call
object
The results of a file search tool call. See the file search guide for more information.


Hide properties
id
string

The unique ID of the file search tool call.

queries
array

The queries used to search for files.

status
string

The status of the file search tool call. One of in_progress, searching, incomplete or failed,

type
string

The type of the file search tool call. Always file_search_call.

results
array or null

The results of the file search tool call.


Show properties
Function tool call
object
A tool call to run a function. See the function calling guide for more information.


Hide properties
arguments
string

A JSON string of the arguments to pass to the function.

call_id
string

The unique ID of the function tool call generated by the model.

name
string

The name of the function to run.

type
string

The type of the function tool call. Always function_call.

id
string

The unique ID of the function tool call.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Web search tool call
object
The results of a web search tool call. See the web search guide for more information.


Hide properties
id
string

The unique ID of the web search tool call.

status
string

The status of the web search tool call.

type
string

The type of the web search tool call. Always web_search_call.

Computer tool call
object
A tool call to a computer use tool. See the computer use guide for more information.


Hide properties
action
object


Show possible types
call_id
string

An identifier used when responding to the tool call with output.

id
string

The unique ID of the computer call.

pending_safety_checks
array

The pending safety checks for the computer call.


Show properties
status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

type
string

The type of the computer call. Always computer_call.

Reasoning
object
A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your input to the Responses API for subsequent turns of a conversation if you are manually managing context.


Hide properties
id
string

The unique identifier of the reasoning content.

summary
array

Reasoning text contents.


Show properties
type
string

The type of the object. Always reasoning.

encrypted_content
string or null

The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Image generation call
object
An image generation request made by the model.


Hide properties
id
string

The unique ID of the image generation call.

result
string or null

The generated image encoded in base64.

status
string

The status of the image generation call.

type
string

The type of the image generation call. Always image_generation_call.

Code interpreter tool call
object
A tool call to run code.


Hide properties
code
string

The code to run.

id
string

The unique ID of the code interpreter tool call.

results
array

The results of the code interpreter tool call.


Show possible types
status
string

The status of the code interpreter tool call.

type
string

The type of the code interpreter tool call. Always code_interpreter_call.

container_id
string

The ID of the container used to run the code.

Local shell call
object
A tool call to run a command on the local shell.


Hide properties
action
object

Execute a shell command on the server.


Show properties
call_id
string

The unique ID of the local shell tool call generated by the model.

id
string

The unique ID of the local shell call.

status
string

The status of the local shell call.

type
string

The type of the local shell call. Always local_shell_call.

MCP tool call
object
An invocation of a tool on an MCP server.


Hide properties
arguments
string

A JSON string of the arguments passed to the tool.

id
string

The unique ID of the tool call.

name
string

The name of the tool that was run.

server_label
string

The label of the MCP server running the tool.

type
string

The type of the item. Always mcp_call.

error
string or null

The error from the tool call, if any.

output
string or null

The output from the tool call.

MCP list tools
object
A list of tools available on an MCP server.


Hide properties
id
string

The unique ID of the list.

server_label
string

The label of the MCP server.

tools
array

The tools available on the server.


Show properties
type
string

The type of the item. Always mcp_list_tools.

error
string or null

Error message if the server could not list tools.

MCP approval request
object
A request for human approval of a tool invocation.


Hide properties
arguments
string

A JSON string of arguments for the tool.

id
string

The unique ID of the approval request.

name
string

The name of the tool to run.

server_label
string

The label of the MCP server making the request.

type
string

The type of the item. Always mcp_approval_request.

parallel_tool_calls
boolean

Whether to allow the model to run tool calls in parallel.

temperature
number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.

tool_choice
string or object

How the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how to specify which tools the model can call.


Hide possible types
Tool choice mode
string
Controls which (if any) tool is called by the model.

none means the model will not call any tool and instead generates a message.

auto means the model can pick between generating a message or calling one or more tools.

required means the model must call one or more tools.

Hosted tool
object
Indicates that the model should use a built-in tool to generate a response. Learn more about built-in tools.


Hide properties
type
string

The type of hosted tool the model should to use. Learn more about built-in tools.

Allowed values are:

file_search
web_search_preview
computer_use_preview
code_interpreter
mcp
image_generation
Function tool
object
Use this option to force the model to call a specific function.


Hide properties
name
string

The name of the function to call.

type
string

For function calling, the type is always function.

tools
array

An array of tools the model may call while generating a response. You can specify which tool to use by setting the tool_choice parameter.

The two categories of tools you can provide the model are:

Built-in tools: Tools that are provided by OpenAI that extend the model's capabilities, like web search or file search. Learn more about built-in tools.
Function calls (custom tools): Functions that are defined by you, enabling the model to call your own code. Learn more about function calling.

Hide possible types
Function
object
Defines a function in your own code the model can choose to call. Learn more about function calling.


Hide properties
name
string

The name of the function to call.

parameters
object

A JSON schema object describing the parameters of the function.

strict
boolean

Whether to enforce strict parameter validation. Default true.

type
string

The type of the function tool. Always function.

description
string

A description of the function. Used by the model to determine whether or not to call the function.

File search
object
A tool that searches for relevant content from uploaded files. Learn more about the file search tool.


Hide properties
type
string

The type of the file search tool. Always file_search.

vector_store_ids
array

The IDs of the vector stores to search.

filters
object

A filter to apply.


Show possible types
max_num_results
integer

The maximum number of results to return. This number should be between 1 and 50 inclusive.

ranking_options
object

Ranking options for search.


Show properties
Web search preview
object
This tool searches the web for relevant results to use in a response. Learn more about the web search tool.


Hide properties
type
string

The type of the web search tool. One of web_search_preview or web_search_preview_2025_03_11.

search_context_size
string

High level guidance for the amount of context window space to use for the search. One of low, medium, or high. medium is the default.

user_location
object

The user's location.


Show properties
Computer use preview
object
A tool that controls a virtual computer. Learn more about the computer tool.


Hide properties
display_height
integer

The height of the computer display.

display_width
integer

The width of the computer display.

environment
string

The type of computer environment to control.

type
string

The type of the computer use tool. Always computer_use_preview.

MCP tool
object
Give the model access to additional tools via remote Model Context Protocol (MCP) servers. Learn more about MCP.


Hide properties
server_label
string

A label for this MCP server, used to identify it in tool calls.

server_url
string

The URL for the MCP server.

type
string

The type of the MCP tool. Always mcp.

allowed_tools
array or object

List of allowed tool names or a filter object.


Show possible types
headers
object or null

Optional HTTP headers to send to the MCP server. Use for authentication or other purposes.

require_approval
object or string

Specify which of the MCP server's tools require approval.


Show possible types
Code interpreter
object
A tool that runs Python code to help generate a response to a prompt.


Hide properties
container
string or object

The code interpreter container. Can be a container ID or an object that specifies uploaded file IDs to make available to your code.


Show possible types
type
string

The type of the code interpreter tool. Always code_interpreter.

Image generation tool
object
A tool that generates images using a model like gpt-image-1.


Hide properties
type
string

The type of the image generation tool. Always image_generation.

background
string

Background type for the generated image. One of transparent, opaque, or auto. Default: auto.

input_image_mask
object

Optional mask for inpainting. Contains image_url (string, optional) and file_id (string, optional).


Show properties
model
string

The image generation model to use. Default: gpt-image-1.

moderation
string

Moderation level for the generated image. Default: auto.

output_compression
integer

Compression level for the output image. Default: 100.

output_format
string

The output format of the generated image. One of png, webp, or jpeg. Default: png.

partial_images
integer

Number of partial images to generate in streaming mode, from 0 (default value) to 3.

quality
string

The quality of the generated image. One of low, medium, high, or auto. Default: auto.

size
string

The size of the generated image. One of 1024x1024, 1024x1536, 1536x1024, or auto. Default: auto.

Local shell tool
object
A tool that allows the model to execute shell commands in a local environment.


Hide properties
type
string

The type of the local shell tool. Always local_shell.

top_p
number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

background
boolean or null

Whether to run the model response in the background. Learn more.

max_output_tokens
integer or null

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.

output_text
string or null

SDK Only
SDK-only convenience property that contains the aggregated text output from all output_text items in the output array, if any are present. Supported in the Python and JavaScript SDKs.

previous_response_id
string or null

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about conversation state.

reasoning
object or null

o-series models only

Configuration options for reasoning models.


Hide properties
effort
string or null

o-series models only

Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

generate_summary
Deprecated
string or null

Deprecated: use summary instead.

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

summary
string or null

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

service_tier
string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.
When not set, the default behavior is 'auto'.
When this parameter is set, the response body will include the service_tier utilized.

status
string

The status of the response generation. One of completed, failed, in_progress, cancelled, queued, or incomplete.

text
object

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

Text inputs and outputs
Structured Outputs

Hide properties
format
object

An object specifying the format that the model must output.

Configuring { "type": "json_schema" } enables Structured Outputs, which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

The default format is { "type": "text" } with no additional options.

Not recommended for gpt-4o and newer models:

Setting to { "type": "json_object" } enables the older JSON mode, which ensures the message the model generates is valid JSON. Using json_schema is preferred for models that support it.


Hide possible types
Text
object
Default response format. Used to generate text responses.


Show properties
JSON schema
object
JSON Schema response format. Used to generate structured JSON responses. Learn more about Structured Outputs.


Show properties
JSON object
object
JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.


Show properties
truncation
string or null

The truncation strategy to use for the model response.

auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
disabled (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.
usage
object

Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.


Hide properties
input_tokens
integer

The number of input tokens.

input_tokens_details
object

A detailed breakdown of the input tokens.


Hide properties
cached_tokens
integer

The number of tokens that were retrieved from the cache. More on prompt caching.

output_tokens
integer

The number of output tokens.

output_tokens_details
object

A detailed breakdown of the output tokens.


Hide properties
reasoning_tokens
integer

The number of reasoning tokens.

total_tokens
integer

The total number of tokens used.

user
string

A stable identifier for your end-users. Used to boost cache hit rates by better bucketing similar requests and to help OpenAI detect and prevent abuse. Learn more.

sequence_number
integer

The sequence number for this event.

type
string

The type of the event. Always response.created.

OBJECT response.created
{
  "type": "response.created",
  "response": {
    "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
    "object": "response",
    "created_at": 1741487325,
    "status": "in_progress",
    "error": null,
    "incomplete_details": null,
    "instructions": null,
    "max_output_tokens": null,
    "model": "gpt-4o-2024-08-06",
    "output": [],
    "parallel_tool_calls": true,
    "previous_response_id": null,
    "reasoning": {
      "effort": null,
      "summary": null
    },
    "store": true,
    "temperature": 1,
    "text": {
      "format": {
        "type": "text"
      }
    },
    "tool_choice": "auto",
    "tools": [],
    "top_p": 1,
    "truncation": "disabled",
    "usage": null,
    "user": null,
    "metadata": {}
  },
  "sequence_number": 1
}
response.in_progress
Emitted when the response is in progress.

response
object

The response that is in progress.


Hide properties
created_at
number

Unix timestamp (in seconds) of when this Response was created.

error
object or null

An error object returned when the model fails to generate a Response.


Hide properties
code
string

The error code for the response.

message
string

A human-readable description of the error.

id
string

Unique identifier for this Response.

incomplete_details
object or null

Details about why the response is incomplete.


Hide properties
reason
string

The reason why the response is incomplete.

instructions
string or null

Inserts a system (or developer) message as the first item in the model's context.

When using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

model
string

Model ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.

object
string

The object type of this resource - always set to response.

output
array

An array of content items generated by the model.

The length and order of items in the output array is dependent on the model's response.
Rather than accessing the first item in the output array and assuming it's an assistant message with the content generated by the model, you might consider using the output_text property where supported in SDKs.

Hide possible types
Output message
object
An output message from the model.


Hide properties
content
array

The content of the output message.


Show possible types
id
string

The unique ID of the output message.

role
string

The role of the output message. Always assistant.

status
string

The status of the message input. One of in_progress, completed, or incomplete. Populated when input items are returned via API.

type
string

The type of the output message. Always message.

File search tool call
object
The results of a file search tool call. See the file search guide for more information.


Hide properties
id
string

The unique ID of the file search tool call.

queries
array

The queries used to search for files.

status
string

The status of the file search tool call. One of in_progress, searching, incomplete or failed,

type
string

The type of the file search tool call. Always file_search_call.

results
array or null

The results of the file search tool call.


Show properties
Function tool call
object
A tool call to run a function. See the function calling guide for more information.


Hide properties
arguments
string

A JSON string of the arguments to pass to the function.

call_id
string

The unique ID of the function tool call generated by the model.

name
string

The name of the function to run.

type
string

The type of the function tool call. Always function_call.

id
string

The unique ID of the function tool call.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Web search tool call
object
The results of a web search tool call. See the web search guide for more information.


Hide properties
id
string

The unique ID of the web search tool call.

status
string

The status of the web search tool call.

type
string

The type of the web search tool call. Always web_search_call.

Computer tool call
object
A tool call to a computer use tool. See the computer use guide for more information.


Hide properties
action
object


Show possible types
call_id
string

An identifier used when responding to the tool call with output.

id
string

The unique ID of the computer call.

pending_safety_checks
array

The pending safety checks for the computer call.


Show properties
status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

type
string

The type of the computer call. Always computer_call.

Reasoning
object
A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your input to the Responses API for subsequent turns of a conversation if you are manually managing context.


Hide properties
id
string

The unique identifier of the reasoning content.

summary
array

Reasoning text contents.


Show properties
type
string

The type of the object. Always reasoning.

encrypted_content
string or null

The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Image generation call
object
An image generation request made by the model.


Hide properties
id
string

The unique ID of the image generation call.

result
string or null

The generated image encoded in base64.

status
string

The status of the image generation call.

type
string

The type of the image generation call. Always image_generation_call.

Code interpreter tool call
object
A tool call to run code.


Hide properties
code
string

The code to run.

id
string

The unique ID of the code interpreter tool call.

results
array

The results of the code interpreter tool call.


Show possible types
status
string

The status of the code interpreter tool call.

type
string

The type of the code interpreter tool call. Always code_interpreter_call.

container_id
string

The ID of the container used to run the code.

Local shell call
object
A tool call to run a command on the local shell.


Hide properties
action
object

Execute a shell command on the server.


Show properties
call_id
string

The unique ID of the local shell tool call generated by the model.

id
string

The unique ID of the local shell call.

status
string

The status of the local shell call.

type
string

The type of the local shell call. Always local_shell_call.

MCP tool call
object
An invocation of a tool on an MCP server.


Hide properties
arguments
string

A JSON string of the arguments passed to the tool.

id
string

The unique ID of the tool call.

name
string

The name of the tool that was run.

server_label
string

The label of the MCP server running the tool.

type
string

The type of the item. Always mcp_call.

error
string or null

The error from the tool call, if any.

output
string or null

The output from the tool call.

MCP list tools
object
A list of tools available on an MCP server.


Hide properties
id
string

The unique ID of the list.

server_label
string

The label of the MCP server.

tools
array

The tools available on the server.


Show properties
type
string

The type of the item. Always mcp_list_tools.

error
string or null

Error message if the server could not list tools.

MCP approval request
object
A request for human approval of a tool invocation.


Hide properties
arguments
string

A JSON string of arguments for the tool.

id
string

The unique ID of the approval request.

name
string

The name of the tool to run.

server_label
string

The label of the MCP server making the request.

type
string

The type of the item. Always mcp_approval_request.

parallel_tool_calls
boolean

Whether to allow the model to run tool calls in parallel.

temperature
number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.

tool_choice
string or object

How the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how to specify which tools the model can call.


Hide possible types
Tool choice mode
string
Controls which (if any) tool is called by the model.

none means the model will not call any tool and instead generates a message.

auto means the model can pick between generating a message or calling one or more tools.

required means the model must call one or more tools.

Hosted tool
object
Indicates that the model should use a built-in tool to generate a response. Learn more about built-in tools.


Hide properties
type
string

The type of hosted tool the model should to use. Learn more about built-in tools.

Allowed values are:

file_search
web_search_preview
computer_use_preview
code_interpreter
mcp
image_generation
Function tool
object
Use this option to force the model to call a specific function.


Hide properties
name
string

The name of the function to call.

type
string

For function calling, the type is always function.

tools
array

An array of tools the model may call while generating a response. You can specify which tool to use by setting the tool_choice parameter.

The two categories of tools you can provide the model are:

Built-in tools: Tools that are provided by OpenAI that extend the model's capabilities, like web search or file search. Learn more about built-in tools.
Function calls (custom tools): Functions that are defined by you, enabling the model to call your own code. Learn more about function calling.

Hide possible types
Function
object
Defines a function in your own code the model can choose to call. Learn more about function calling.


Hide properties
name
string

The name of the function to call.

parameters
object

A JSON schema object describing the parameters of the function.

strict
boolean

Whether to enforce strict parameter validation. Default true.

type
string

The type of the function tool. Always function.

description
string

A description of the function. Used by the model to determine whether or not to call the function.

File search
object
A tool that searches for relevant content from uploaded files. Learn more about the file search tool.


Hide properties
type
string

The type of the file search tool. Always file_search.

vector_store_ids
array

The IDs of the vector stores to search.

filters
object

A filter to apply.


Show possible types
max_num_results
integer

The maximum number of results to return. This number should be between 1 and 50 inclusive.

ranking_options
object

Ranking options for search.


Show properties
Web search preview
object
This tool searches the web for relevant results to use in a response. Learn more about the web search tool.


Hide properties
type
string

The type of the web search tool. One of web_search_preview or web_search_preview_2025_03_11.

search_context_size
string

High level guidance for the amount of context window space to use for the search. One of low, medium, or high. medium is the default.

user_location
object

The user's location.


Show properties
Computer use preview
object
A tool that controls a virtual computer. Learn more about the computer tool.


Hide properties
display_height
integer

The height of the computer display.

display_width
integer

The width of the computer display.

environment
string

The type of computer environment to control.

type
string

The type of the computer use tool. Always computer_use_preview.

MCP tool
object
Give the model access to additional tools via remote Model Context Protocol (MCP) servers. Learn more about MCP.


Hide properties
server_label
string

A label for this MCP server, used to identify it in tool calls.

server_url
string

The URL for the MCP server.

type
string

The type of the MCP tool. Always mcp.

allowed_tools
array or object

List of allowed tool names or a filter object.


Show possible types
headers
object or null

Optional HTTP headers to send to the MCP server. Use for authentication or other purposes.

require_approval
object or string

Specify which of the MCP server's tools require approval.


Show possible types
Code interpreter
object
A tool that runs Python code to help generate a response to a prompt.


Hide properties
container
string or object

The code interpreter container. Can be a container ID or an object that specifies uploaded file IDs to make available to your code.


Show possible types
type
string

The type of the code interpreter tool. Always code_interpreter.

Image generation tool
object
A tool that generates images using a model like gpt-image-1.


Hide properties
type
string

The type of the image generation tool. Always image_generation.

background
string

Background type for the generated image. One of transparent, opaque, or auto. Default: auto.

input_image_mask
object

Optional mask for inpainting. Contains image_url (string, optional) and file_id (string, optional).


Show properties
model
string

The image generation model to use. Default: gpt-image-1.

moderation
string

Moderation level for the generated image. Default: auto.

output_compression
integer

Compression level for the output image. Default: 100.

output_format
string

The output format of the generated image. One of png, webp, or jpeg. Default: png.

partial_images
integer

Number of partial images to generate in streaming mode, from 0 (default value) to 3.

quality
string

The quality of the generated image. One of low, medium, high, or auto. Default: auto.

size
string

The size of the generated image. One of 1024x1024, 1024x1536, 1536x1024, or auto. Default: auto.

Local shell tool
object
A tool that allows the model to execute shell commands in a local environment.


Hide properties
type
string

The type of the local shell tool. Always local_shell.

top_p
number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

background
boolean or null

Whether to run the model response in the background. Learn more.

max_output_tokens
integer or null

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.

output_text
string or null

SDK Only
SDK-only convenience property that contains the aggregated text output from all output_text items in the output array, if any are present. Supported in the Python and JavaScript SDKs.

previous_response_id
string or null

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about conversation state.

reasoning
object or null

o-series models only

Configuration options for reasoning models.


Hide properties
effort
string or null

o-series models only

Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

generate_summary
Deprecated
string or null

Deprecated: use summary instead.

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

summary
string or null

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

service_tier
string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.
When not set, the default behavior is 'auto'.
When this parameter is set, the response body will include the service_tier utilized.

status
string

The status of the response generation. One of completed, failed, in_progress, cancelled, queued, or incomplete.

text
object

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

Text inputs and outputs
Structured Outputs

Hide properties
format
object

An object specifying the format that the model must output.

Configuring { "type": "json_schema" } enables Structured Outputs, which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

The default format is { "type": "text" } with no additional options.

Not recommended for gpt-4o and newer models:

Setting to { "type": "json_object" } enables the older JSON mode, which ensures the message the model generates is valid JSON. Using json_schema is preferred for models that support it.


Hide possible types
Text
object
Default response format. Used to generate text responses.


Show properties
JSON schema
object
JSON Schema response format. Used to generate structured JSON responses. Learn more about Structured Outputs.


Show properties
JSON object
object
JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.


Show properties
truncation
string or null

The truncation strategy to use for the model response.

auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
disabled (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.
usage
object

Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.


Hide properties
input_tokens
integer

The number of input tokens.

input_tokens_details
object

A detailed breakdown of the input tokens.


Hide properties
cached_tokens
integer

The number of tokens that were retrieved from the cache. More on prompt caching.

output_tokens
integer

The number of output tokens.

output_tokens_details
object

A detailed breakdown of the output tokens.


Hide properties
reasoning_tokens
integer

The number of reasoning tokens.

total_tokens
integer

The total number of tokens used.

user
string

A stable identifier for your end-users. Used to boost cache hit rates by better bucketing similar requests and to help OpenAI detect and prevent abuse. Learn more.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.in_progress.

OBJECT response.in_progress
{
  "type": "response.in_progress",
  "response": {
    "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
    "object": "response",
    "created_at": 1741487325,
    "status": "in_progress",
    "error": null,
    "incomplete_details": null,
    "instructions": null,
    "max_output_tokens": null,
    "model": "gpt-4o-2024-08-06",
    "output": [],
    "parallel_tool_calls": true,
    "previous_response_id": null,
    "reasoning": {
      "effort": null,
      "summary": null
    },
    "store": true,
    "temperature": 1,
    "text": {
      "format": {
        "type": "text"
      }
    },
    "tool_choice": "auto",
    "tools": [],
    "top_p": 1,
    "truncation": "disabled",
    "usage": null,
    "user": null,
    "metadata": {}
  },
  "sequence_number": 1
}
response.completed
Emitted when the model response is complete.

response
object

Properties of the completed response.


Hide properties
created_at
number

Unix timestamp (in seconds) of when this Response was created.

error
object or null

An error object returned when the model fails to generate a Response.


Hide properties
code
string

The error code for the response.

message
string

A human-readable description of the error.

id
string

Unique identifier for this Response.

incomplete_details
object or null

Details about why the response is incomplete.


Hide properties
reason
string

The reason why the response is incomplete.

instructions
string or null

Inserts a system (or developer) message as the first item in the model's context.

When using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

model
string

Model ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.

object
string

The object type of this resource - always set to response.

output
array

An array of content items generated by the model.

The length and order of items in the output array is dependent on the model's response.
Rather than accessing the first item in the output array and assuming it's an assistant message with the content generated by the model, you might consider using the output_text property where supported in SDKs.

Hide possible types
Output message
object
An output message from the model.


Hide properties
content
array

The content of the output message.


Show possible types
id
string

The unique ID of the output message.

role
string

The role of the output message. Always assistant.

status
string

The status of the message input. One of in_progress, completed, or incomplete. Populated when input items are returned via API.

type
string

The type of the output message. Always message.

File search tool call
object
The results of a file search tool call. See the file search guide for more information.


Hide properties
id
string

The unique ID of the file search tool call.

queries
array

The queries used to search for files.

status
string

The status of the file search tool call. One of in_progress, searching, incomplete or failed,

type
string

The type of the file search tool call. Always file_search_call.

results
array or null

The results of the file search tool call.


Show properties
Function tool call
object
A tool call to run a function. See the function calling guide for more information.


Hide properties
arguments
string

A JSON string of the arguments to pass to the function.

call_id
string

The unique ID of the function tool call generated by the model.

name
string

The name of the function to run.

type
string

The type of the function tool call. Always function_call.

id
string

The unique ID of the function tool call.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Web search tool call
object
The results of a web search tool call. See the web search guide for more information.


Hide properties
id
string

The unique ID of the web search tool call.

status
string

The status of the web search tool call.

type
string

The type of the web search tool call. Always web_search_call.

Computer tool call
object
A tool call to a computer use tool. See the computer use guide for more information.


Hide properties
action
object


Show possible types
call_id
string

An identifier used when responding to the tool call with output.

id
string

The unique ID of the computer call.

pending_safety_checks
array

The pending safety checks for the computer call.


Show properties
status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

type
string

The type of the computer call. Always computer_call.

Reasoning
object
A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your input to the Responses API for subsequent turns of a conversation if you are manually managing context.


Hide properties
id
string

The unique identifier of the reasoning content.

summary
array

Reasoning text contents.


Show properties
type
string

The type of the object. Always reasoning.

encrypted_content
string or null

The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Image generation call
object
An image generation request made by the model.


Hide properties
id
string

The unique ID of the image generation call.

result
string or null

The generated image encoded in base64.

status
string

The status of the image generation call.

type
string

The type of the image generation call. Always image_generation_call.

Code interpreter tool call
object
A tool call to run code.


Hide properties
code
string

The code to run.

id
string

The unique ID of the code interpreter tool call.

results
array

The results of the code interpreter tool call.


Show possible types
status
string

The status of the code interpreter tool call.

type
string

The type of the code interpreter tool call. Always code_interpreter_call.

container_id
string

The ID of the container used to run the code.

Local shell call
object
A tool call to run a command on the local shell.


Hide properties
action
object

Execute a shell command on the server.


Show properties
call_id
string

The unique ID of the local shell tool call generated by the model.

id
string

The unique ID of the local shell call.

status
string

The status of the local shell call.

type
string

The type of the local shell call. Always local_shell_call.

MCP tool call
object
An invocation of a tool on an MCP server.


Hide properties
arguments
string

A JSON string of the arguments passed to the tool.

id
string

The unique ID of the tool call.

name
string

The name of the tool that was run.

server_label
string

The label of the MCP server running the tool.

type
string

The type of the item. Always mcp_call.

error
string or null

The error from the tool call, if any.

output
string or null

The output from the tool call.

MCP list tools
object
A list of tools available on an MCP server.


Hide properties
id
string

The unique ID of the list.

server_label
string

The label of the MCP server.

tools
array

The tools available on the server.


Show properties
type
string

The type of the item. Always mcp_list_tools.

error
string or null

Error message if the server could not list tools.

MCP approval request
object
A request for human approval of a tool invocation.


Hide properties
arguments
string

A JSON string of arguments for the tool.

id
string

The unique ID of the approval request.

name
string

The name of the tool to run.

server_label
string

The label of the MCP server making the request.

type
string

The type of the item. Always mcp_approval_request.

parallel_tool_calls
boolean

Whether to allow the model to run tool calls in parallel.

temperature
number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.

tool_choice
string or object

How the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how to specify which tools the model can call.


Hide possible types
Tool choice mode
string
Controls which (if any) tool is called by the model.

none means the model will not call any tool and instead generates a message.

auto means the model can pick between generating a message or calling one or more tools.

required means the model must call one or more tools.

Hosted tool
object
Indicates that the model should use a built-in tool to generate a response. Learn more about built-in tools.


Hide properties
type
string

The type of hosted tool the model should to use. Learn more about built-in tools.

Allowed values are:

file_search
web_search_preview
computer_use_preview
code_interpreter
mcp
image_generation
Function tool
object
Use this option to force the model to call a specific function.


Hide properties
name
string

The name of the function to call.

type
string

For function calling, the type is always function.

tools
array

An array of tools the model may call while generating a response. You can specify which tool to use by setting the tool_choice parameter.

The two categories of tools you can provide the model are:

Built-in tools: Tools that are provided by OpenAI that extend the model's capabilities, like web search or file search. Learn more about built-in tools.
Function calls (custom tools): Functions that are defined by you, enabling the model to call your own code. Learn more about function calling.

Hide possible types
Function
object
Defines a function in your own code the model can choose to call. Learn more about function calling.


Hide properties
name
string

The name of the function to call.

parameters
object

A JSON schema object describing the parameters of the function.

strict
boolean

Whether to enforce strict parameter validation. Default true.

type
string

The type of the function tool. Always function.

description
string

A description of the function. Used by the model to determine whether or not to call the function.

File search
object
A tool that searches for relevant content from uploaded files. Learn more about the file search tool.


Hide properties
type
string

The type of the file search tool. Always file_search.

vector_store_ids
array

The IDs of the vector stores to search.

filters
object

A filter to apply.


Show possible types
max_num_results
integer

The maximum number of results to return. This number should be between 1 and 50 inclusive.

ranking_options
object

Ranking options for search.


Show properties
Web search preview
object
This tool searches the web for relevant results to use in a response. Learn more about the web search tool.


Hide properties
type
string

The type of the web search tool. One of web_search_preview or web_search_preview_2025_03_11.

search_context_size
string

High level guidance for the amount of context window space to use for the search. One of low, medium, or high. medium is the default.

user_location
object

The user's location.


Show properties
Computer use preview
object
A tool that controls a virtual computer. Learn more about the computer tool.


Hide properties
display_height
integer

The height of the computer display.

display_width
integer

The width of the computer display.

environment
string

The type of computer environment to control.

type
string

The type of the computer use tool. Always computer_use_preview.

MCP tool
object
Give the model access to additional tools via remote Model Context Protocol (MCP) servers. Learn more about MCP.


Hide properties
server_label
string

A label for this MCP server, used to identify it in tool calls.

server_url
string

The URL for the MCP server.

type
string

The type of the MCP tool. Always mcp.

allowed_tools
array or object

List of allowed tool names or a filter object.


Show possible types
headers
object or null

Optional HTTP headers to send to the MCP server. Use for authentication or other purposes.

require_approval
object or string

Specify which of the MCP server's tools require approval.


Show possible types
Code interpreter
object
A tool that runs Python code to help generate a response to a prompt.


Hide properties
container
string or object

The code interpreter container. Can be a container ID or an object that specifies uploaded file IDs to make available to your code.


Show possible types
type
string

The type of the code interpreter tool. Always code_interpreter.

Image generation tool
object
A tool that generates images using a model like gpt-image-1.


Hide properties
type
string

The type of the image generation tool. Always image_generation.

background
string

Background type for the generated image. One of transparent, opaque, or auto. Default: auto.

input_image_mask
object

Optional mask for inpainting. Contains image_url (string, optional) and file_id (string, optional).


Show properties
model
string

The image generation model to use. Default: gpt-image-1.

moderation
string

Moderation level for the generated image. Default: auto.

output_compression
integer

Compression level for the output image. Default: 100.

output_format
string

The output format of the generated image. One of png, webp, or jpeg. Default: png.

partial_images
integer

Number of partial images to generate in streaming mode, from 0 (default value) to 3.

quality
string

The quality of the generated image. One of low, medium, high, or auto. Default: auto.

size
string

The size of the generated image. One of 1024x1024, 1024x1536, 1536x1024, or auto. Default: auto.

Local shell tool
object
A tool that allows the model to execute shell commands in a local environment.


Hide properties
type
string

The type of the local shell tool. Always local_shell.

top_p
number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

background
boolean or null

Whether to run the model response in the background. Learn more.

max_output_tokens
integer or null

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.

output_text
string or null

SDK Only
SDK-only convenience property that contains the aggregated text output from all output_text items in the output array, if any are present. Supported in the Python and JavaScript SDKs.

previous_response_id
string or null

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about conversation state.

reasoning
object or null

o-series models only

Configuration options for reasoning models.


Hide properties
effort
string or null

o-series models only

Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

generate_summary
Deprecated
string or null

Deprecated: use summary instead.

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

summary
string or null

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

service_tier
string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.
When not set, the default behavior is 'auto'.
When this parameter is set, the response body will include the service_tier utilized.

status
string

The status of the response generation. One of completed, failed, in_progress, cancelled, queued, or incomplete.

text
object

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

Text inputs and outputs
Structured Outputs

Hide properties
format
object

An object specifying the format that the model must output.

Configuring { "type": "json_schema" } enables Structured Outputs, which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

The default format is { "type": "text" } with no additional options.

Not recommended for gpt-4o and newer models:

Setting to { "type": "json_object" } enables the older JSON mode, which ensures the message the model generates is valid JSON. Using json_schema is preferred for models that support it.


Hide possible types
Text
object
Default response format. Used to generate text responses.


Show properties
JSON schema
object
JSON Schema response format. Used to generate structured JSON responses. Learn more about Structured Outputs.


Show properties
JSON object
object
JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.


Show properties
truncation
string or null

The truncation strategy to use for the model response.

auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
disabled (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.
usage
object

Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.


Hide properties
input_tokens
integer

The number of input tokens.

input_tokens_details
object

A detailed breakdown of the input tokens.


Hide properties
cached_tokens
integer

The number of tokens that were retrieved from the cache. More on prompt caching.

output_tokens
integer

The number of output tokens.

output_tokens_details
object

A detailed breakdown of the output tokens.


Hide properties
reasoning_tokens
integer

The number of reasoning tokens.

total_tokens
integer

The total number of tokens used.

user
string

A stable identifier for your end-users. Used to boost cache hit rates by better bucketing similar requests and to help OpenAI detect and prevent abuse. Learn more.

sequence_number
integer

The sequence number for this event.

type
string

The type of the event. Always response.completed.

OBJECT response.completed
{
  "type": "response.completed",
  "response": {
    "id": "resp_123",
    "object": "response",
    "created_at": 1740855869,
    "status": "completed",
    "error": null,
    "incomplete_details": null,
    "input": [],
    "instructions": null,
    "max_output_tokens": null,
    "model": "gpt-4o-mini-2024-07-18",
    "output": [
      {
        "id": "msg_123",
        "type": "message",
        "role": "assistant",
        "content": [
          {
            "type": "output_text",
            "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
            "annotations": []
          }
        ]
      }
    ],
    "previous_response_id": null,
    "reasoning_effort": null,
    "store": false,
    "temperature": 1,
    "text": {
      "format": {
        "type": "text"
      }
    },
    "tool_choice": "auto",
    "tools": [],
    "top_p": 1,
    "truncation": "disabled",
    "usage": {
      "input_tokens": 0,
      "output_tokens": 0,
      "output_tokens_details": {
        "reasoning_tokens": 0
      },
      "total_tokens": 0
    },
    "user": null,
    "metadata": {}
  },
  "sequence_number": 1
}
response.failed
An event that is emitted when a response fails.

response
object

The response that failed.


Hide properties
created_at
number

Unix timestamp (in seconds) of when this Response was created.

error
object or null

An error object returned when the model fails to generate a Response.


Hide properties
code
string

The error code for the response.

message
string

A human-readable description of the error.

id
string

Unique identifier for this Response.

incomplete_details
object or null

Details about why the response is incomplete.


Hide properties
reason
string

The reason why the response is incomplete.

instructions
string or null

Inserts a system (or developer) message as the first item in the model's context.

When using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

model
string

Model ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.

object
string

The object type of this resource - always set to response.

output
array

An array of content items generated by the model.

The length and order of items in the output array is dependent on the model's response.
Rather than accessing the first item in the output array and assuming it's an assistant message with the content generated by the model, you might consider using the output_text property where supported in SDKs.

Hide possible types
Output message
object
An output message from the model.


Hide properties
content
array

The content of the output message.


Show possible types
id
string

The unique ID of the output message.

role
string

The role of the output message. Always assistant.

status
string

The status of the message input. One of in_progress, completed, or incomplete. Populated when input items are returned via API.

type
string

The type of the output message. Always message.

File search tool call
object
The results of a file search tool call. See the file search guide for more information.


Hide properties
id
string

The unique ID of the file search tool call.

queries
array

The queries used to search for files.

status
string

The status of the file search tool call. One of in_progress, searching, incomplete or failed,

type
string

The type of the file search tool call. Always file_search_call.

results
array or null

The results of the file search tool call.


Show properties
Function tool call
object
A tool call to run a function. See the function calling guide for more information.


Hide properties
arguments
string

A JSON string of the arguments to pass to the function.

call_id
string

The unique ID of the function tool call generated by the model.

name
string

The name of the function to run.

type
string

The type of the function tool call. Always function_call.

id
string

The unique ID of the function tool call.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Web search tool call
object
The results of a web search tool call. See the web search guide for more information.


Hide properties
id
string

The unique ID of the web search tool call.

status
string

The status of the web search tool call.

type
string

The type of the web search tool call. Always web_search_call.

Computer tool call
object
A tool call to a computer use tool. See the computer use guide for more information.


Hide properties
action
object


Show possible types
call_id
string

An identifier used when responding to the tool call with output.

id
string

The unique ID of the computer call.

pending_safety_checks
array

The pending safety checks for the computer call.


Show properties
status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

type
string

The type of the computer call. Always computer_call.

Reasoning
object
A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your input to the Responses API for subsequent turns of a conversation if you are manually managing context.


Hide properties
id
string

The unique identifier of the reasoning content.

summary
array

Reasoning text contents.


Show properties
type
string

The type of the object. Always reasoning.

encrypted_content
string or null

The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Image generation call
object
An image generation request made by the model.


Hide properties
id
string

The unique ID of the image generation call.

result
string or null

The generated image encoded in base64.

status
string

The status of the image generation call.

type
string

The type of the image generation call. Always image_generation_call.

Code interpreter tool call
object
A tool call to run code.


Hide properties
code
string

The code to run.

id
string

The unique ID of the code interpreter tool call.

results
array

The results of the code interpreter tool call.


Show possible types
status
string

The status of the code interpreter tool call.

type
string

The type of the code interpreter tool call. Always code_interpreter_call.

container_id
string

The ID of the container used to run the code.

Local shell call
object
A tool call to run a command on the local shell.


Hide properties
action
object

Execute a shell command on the server.


Show properties
call_id
string

The unique ID of the local shell tool call generated by the model.

id
string

The unique ID of the local shell call.

status
string

The status of the local shell call.

type
string

The type of the local shell call. Always local_shell_call.

MCP tool call
object
An invocation of a tool on an MCP server.


Hide properties
arguments
string

A JSON string of the arguments passed to the tool.

id
string

The unique ID of the tool call.

name
string

The name of the tool that was run.

server_label
string

The label of the MCP server running the tool.

type
string

The type of the item. Always mcp_call.

error
string or null

The error from the tool call, if any.

output
string or null

The output from the tool call.

MCP list tools
object
A list of tools available on an MCP server.


Hide properties
id
string

The unique ID of the list.

server_label
string

The label of the MCP server.

tools
array

The tools available on the server.


Show properties
type
string

The type of the item. Always mcp_list_tools.

error
string or null

Error message if the server could not list tools.

MCP approval request
object
A request for human approval of a tool invocation.


Hide properties
arguments
string

A JSON string of arguments for the tool.

id
string

The unique ID of the approval request.

name
string

The name of the tool to run.

server_label
string

The label of the MCP server making the request.

type
string

The type of the item. Always mcp_approval_request.

parallel_tool_calls
boolean

Whether to allow the model to run tool calls in parallel.

temperature
number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.

tool_choice
string or object

How the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how to specify which tools the model can call.


Hide possible types
Tool choice mode
string
Controls which (if any) tool is called by the model.

none means the model will not call any tool and instead generates a message.

auto means the model can pick between generating a message or calling one or more tools.

required means the model must call one or more tools.

Hosted tool
object
Indicates that the model should use a built-in tool to generate a response. Learn more about built-in tools.


Hide properties
type
string

The type of hosted tool the model should to use. Learn more about built-in tools.

Allowed values are:

file_search
web_search_preview
computer_use_preview
code_interpreter
mcp
image_generation
Function tool
object
Use this option to force the model to call a specific function.


Hide properties
name
string

The name of the function to call.

type
string

For function calling, the type is always function.

tools
array

An array of tools the model may call while generating a response. You can specify which tool to use by setting the tool_choice parameter.

The two categories of tools you can provide the model are:

Built-in tools: Tools that are provided by OpenAI that extend the model's capabilities, like web search or file search. Learn more about built-in tools.
Function calls (custom tools): Functions that are defined by you, enabling the model to call your own code. Learn more about function calling.

Hide possible types
Function
object
Defines a function in your own code the model can choose to call. Learn more about function calling.


Hide properties
name
string

The name of the function to call.

parameters
object

A JSON schema object describing the parameters of the function.

strict
boolean

Whether to enforce strict parameter validation. Default true.

type
string

The type of the function tool. Always function.

description
string

A description of the function. Used by the model to determine whether or not to call the function.

File search
object
A tool that searches for relevant content from uploaded files. Learn more about the file search tool.


Hide properties
type
string

The type of the file search tool. Always file_search.

vector_store_ids
array

The IDs of the vector stores to search.

filters
object

A filter to apply.


Show possible types
max_num_results
integer

The maximum number of results to return. This number should be between 1 and 50 inclusive.

ranking_options
object

Ranking options for search.


Show properties
Web search preview
object
This tool searches the web for relevant results to use in a response. Learn more about the web search tool.


Hide properties
type
string

The type of the web search tool. One of web_search_preview or web_search_preview_2025_03_11.

search_context_size
string

High level guidance for the amount of context window space to use for the search. One of low, medium, or high. medium is the default.

user_location
object

The user's location.


Show properties
Computer use preview
object
A tool that controls a virtual computer. Learn more about the computer tool.


Hide properties
display_height
integer

The height of the computer display.

display_width
integer

The width of the computer display.

environment
string

The type of computer environment to control.

type
string

The type of the computer use tool. Always computer_use_preview.

MCP tool
object
Give the model access to additional tools via remote Model Context Protocol (MCP) servers. Learn more about MCP.


Hide properties
server_label
string

A label for this MCP server, used to identify it in tool calls.

server_url
string

The URL for the MCP server.

type
string

The type of the MCP tool. Always mcp.

allowed_tools
array or object

List of allowed tool names or a filter object.


Show possible types
headers
object or null

Optional HTTP headers to send to the MCP server. Use for authentication or other purposes.

require_approval
object or string

Specify which of the MCP server's tools require approval.


Show possible types
Code interpreter
object
A tool that runs Python code to help generate a response to a prompt.


Hide properties
container
string or object

The code interpreter container. Can be a container ID or an object that specifies uploaded file IDs to make available to your code.


Show possible types
type
string

The type of the code interpreter tool. Always code_interpreter.

Image generation tool
object
A tool that generates images using a model like gpt-image-1.


Hide properties
type
string

The type of the image generation tool. Always image_generation.

background
string

Background type for the generated image. One of transparent, opaque, or auto. Default: auto.

input_image_mask
object

Optional mask for inpainting. Contains image_url (string, optional) and file_id (string, optional).


Show properties
model
string

The image generation model to use. Default: gpt-image-1.

moderation
string

Moderation level for the generated image. Default: auto.

output_compression
integer

Compression level for the output image. Default: 100.

output_format
string

The output format of the generated image. One of png, webp, or jpeg. Default: png.

partial_images
integer

Number of partial images to generate in streaming mode, from 0 (default value) to 3.

quality
string

The quality of the generated image. One of low, medium, high, or auto. Default: auto.

size
string

The size of the generated image. One of 1024x1024, 1024x1536, 1536x1024, or auto. Default: auto.

Local shell tool
object
A tool that allows the model to execute shell commands in a local environment.


Hide properties
type
string

The type of the local shell tool. Always local_shell.

top_p
number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

background
boolean or null

Whether to run the model response in the background. Learn more.

max_output_tokens
integer or null

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.

output_text
string or null

SDK Only
SDK-only convenience property that contains the aggregated text output from all output_text items in the output array, if any are present. Supported in the Python and JavaScript SDKs.

previous_response_id
string or null

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about conversation state.

reasoning
object or null

o-series models only

Configuration options for reasoning models.


Hide properties
effort
string or null

o-series models only

Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

generate_summary
Deprecated
string or null

Deprecated: use summary instead.

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

summary
string or null

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

service_tier
string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.
When not set, the default behavior is 'auto'.
When this parameter is set, the response body will include the service_tier utilized.

status
string

The status of the response generation. One of completed, failed, in_progress, cancelled, queued, or incomplete.

text
object

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

Text inputs and outputs
Structured Outputs

Hide properties
format
object

An object specifying the format that the model must output.

Configuring { "type": "json_schema" } enables Structured Outputs, which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

The default format is { "type": "text" } with no additional options.

Not recommended for gpt-4o and newer models:

Setting to { "type": "json_object" } enables the older JSON mode, which ensures the message the model generates is valid JSON. Using json_schema is preferred for models that support it.


Hide possible types
Text
object
Default response format. Used to generate text responses.


Show properties
JSON schema
object
JSON Schema response format. Used to generate structured JSON responses. Learn more about Structured Outputs.


Show properties
JSON object
object
JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.


Show properties
truncation
string or null

The truncation strategy to use for the model response.

auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
disabled (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.
usage
object

Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.


Hide properties
input_tokens
integer

The number of input tokens.

input_tokens_details
object

A detailed breakdown of the input tokens.


Hide properties
cached_tokens
integer

The number of tokens that were retrieved from the cache. More on prompt caching.

output_tokens
integer

The number of output tokens.

output_tokens_details
object

A detailed breakdown of the output tokens.


Hide properties
reasoning_tokens
integer

The number of reasoning tokens.

total_tokens
integer

The total number of tokens used.

user
string

A stable identifier for your end-users. Used to boost cache hit rates by better bucketing similar requests and to help OpenAI detect and prevent abuse. Learn more.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.failed.

OBJECT response.failed
{
  "type": "response.failed",
  "response": {
    "id": "resp_123",
    "object": "response",
    "created_at": 1740855869,
    "status": "failed",
    "error": {
      "code": "server_error",
      "message": "The model failed to generate a response."
    },
    "incomplete_details": null,
    "instructions": null,
    "max_output_tokens": null,
    "model": "gpt-4o-mini-2024-07-18",
    "output": [],
    "previous_response_id": null,
    "reasoning_effort": null,
    "store": false,
    "temperature": 1,
    "text": {
      "format": {
        "type": "text"
      }
    },
    "tool_choice": "auto",
    "tools": [],
    "top_p": 1,
    "truncation": "disabled",
    "usage": null,
    "user": null,
    "metadata": {}
  }
}
response.incomplete
An event that is emitted when a response finishes as incomplete.

response
object

The response that was incomplete.


Hide properties
created_at
number

Unix timestamp (in seconds) of when this Response was created.

error
object or null

An error object returned when the model fails to generate a Response.


Hide properties
code
string

The error code for the response.

message
string

A human-readable description of the error.

id
string

Unique identifier for this Response.

incomplete_details
object or null

Details about why the response is incomplete.


Hide properties
reason
string

The reason why the response is incomplete.

instructions
string or null

Inserts a system (or developer) message as the first item in the model's context.

When using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

model
string

Model ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.

object
string

The object type of this resource - always set to response.

output
array

An array of content items generated by the model.

The length and order of items in the output array is dependent on the model's response.
Rather than accessing the first item in the output array and assuming it's an assistant message with the content generated by the model, you might consider using the output_text property where supported in SDKs.

Hide possible types
Output message
object
An output message from the model.


Hide properties
content
array

The content of the output message.


Show possible types
id
string

The unique ID of the output message.

role
string

The role of the output message. Always assistant.

status
string

The status of the message input. One of in_progress, completed, or incomplete. Populated when input items are returned via API.

type
string

The type of the output message. Always message.

File search tool call
object
The results of a file search tool call. See the file search guide for more information.


Hide properties
id
string

The unique ID of the file search tool call.

queries
array

The queries used to search for files.

status
string

The status of the file search tool call. One of in_progress, searching, incomplete or failed,

type
string

The type of the file search tool call. Always file_search_call.

results
array or null

The results of the file search tool call.


Show properties
Function tool call
object
A tool call to run a function. See the function calling guide for more information.


Hide properties
arguments
string

A JSON string of the arguments to pass to the function.

call_id
string

The unique ID of the function tool call generated by the model.

name
string

The name of the function to run.

type
string

The type of the function tool call. Always function_call.

id
string

The unique ID of the function tool call.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Web search tool call
object
The results of a web search tool call. See the web search guide for more information.


Hide properties
id
string

The unique ID of the web search tool call.

status
string

The status of the web search tool call.

type
string

The type of the web search tool call. Always web_search_call.

Computer tool call
object
A tool call to a computer use tool. See the computer use guide for more information.


Hide properties
action
object


Show possible types
call_id
string

An identifier used when responding to the tool call with output.

id
string

The unique ID of the computer call.

pending_safety_checks
array

The pending safety checks for the computer call.


Show properties
status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

type
string

The type of the computer call. Always computer_call.

Reasoning
object
A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your input to the Responses API for subsequent turns of a conversation if you are manually managing context.


Hide properties
id
string

The unique identifier of the reasoning content.

summary
array

Reasoning text contents.


Show properties
type
string

The type of the object. Always reasoning.

encrypted_content
string or null

The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Image generation call
object
An image generation request made by the model.


Hide properties
id
string

The unique ID of the image generation call.

result
string or null

The generated image encoded in base64.

status
string

The status of the image generation call.

type
string

The type of the image generation call. Always image_generation_call.

Code interpreter tool call
object
A tool call to run code.


Hide properties
code
string

The code to run.

id
string

The unique ID of the code interpreter tool call.

results
array

The results of the code interpreter tool call.


Show possible types
status
string

The status of the code interpreter tool call.

type
string

The type of the code interpreter tool call. Always code_interpreter_call.

container_id
string

The ID of the container used to run the code.

Local shell call
object
A tool call to run a command on the local shell.


Hide properties
action
object

Execute a shell command on the server.


Show properties
call_id
string

The unique ID of the local shell tool call generated by the model.

id
string

The unique ID of the local shell call.

status
string

The status of the local shell call.

type
string

The type of the local shell call. Always local_shell_call.

MCP tool call
object
An invocation of a tool on an MCP server.


Hide properties
arguments
string

A JSON string of the arguments passed to the tool.

id
string

The unique ID of the tool call.

name
string

The name of the tool that was run.

server_label
string

The label of the MCP server running the tool.

type
string

The type of the item. Always mcp_call.

error
string or null

The error from the tool call, if any.

output
string or null

The output from the tool call.

MCP list tools
object
A list of tools available on an MCP server.


Hide properties
id
string

The unique ID of the list.

server_label
string

The label of the MCP server.

tools
array

The tools available on the server.


Show properties
type
string

The type of the item. Always mcp_list_tools.

error
string or null

Error message if the server could not list tools.

MCP approval request
object
A request for human approval of a tool invocation.


Hide properties
arguments
string

A JSON string of arguments for the tool.

id
string

The unique ID of the approval request.

name
string

The name of the tool to run.

server_label
string

The label of the MCP server making the request.

type
string

The type of the item. Always mcp_approval_request.

parallel_tool_calls
boolean

Whether to allow the model to run tool calls in parallel.

temperature
number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.

tool_choice
string or object

How the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how to specify which tools the model can call.


Hide possible types
Tool choice mode
string
Controls which (if any) tool is called by the model.

none means the model will not call any tool and instead generates a message.

auto means the model can pick between generating a message or calling one or more tools.

required means the model must call one or more tools.

Hosted tool
object
Indicates that the model should use a built-in tool to generate a response. Learn more about built-in tools.


Hide properties
type
string

The type of hosted tool the model should to use. Learn more about built-in tools.

Allowed values are:

file_search
web_search_preview
computer_use_preview
code_interpreter
mcp
image_generation
Function tool
object
Use this option to force the model to call a specific function.


Hide properties
name
string

The name of the function to call.

type
string

For function calling, the type is always function.

tools
array

An array of tools the model may call while generating a response. You can specify which tool to use by setting the tool_choice parameter.

The two categories of tools you can provide the model are:

Built-in tools: Tools that are provided by OpenAI that extend the model's capabilities, like web search or file search. Learn more about built-in tools.
Function calls (custom tools): Functions that are defined by you, enabling the model to call your own code. Learn more about function calling.

Hide possible types
Function
object
Defines a function in your own code the model can choose to call. Learn more about function calling.


Hide properties
name
string

The name of the function to call.

parameters
object

A JSON schema object describing the parameters of the function.

strict
boolean

Whether to enforce strict parameter validation. Default true.

type
string

The type of the function tool. Always function.

description
string

A description of the function. Used by the model to determine whether or not to call the function.

File search
object
A tool that searches for relevant content from uploaded files. Learn more about the file search tool.


Hide properties
type
string

The type of the file search tool. Always file_search.

vector_store_ids
array

The IDs of the vector stores to search.

filters
object

A filter to apply.


Show possible types
max_num_results
integer

The maximum number of results to return. This number should be between 1 and 50 inclusive.

ranking_options
object

Ranking options for search.


Show properties
Web search preview
object
This tool searches the web for relevant results to use in a response. Learn more about the web search tool.


Hide properties
type
string

The type of the web search tool. One of web_search_preview or web_search_preview_2025_03_11.

search_context_size
string

High level guidance for the amount of context window space to use for the search. One of low, medium, or high. medium is the default.

user_location
object

The user's location.


Show properties
Computer use preview
object
A tool that controls a virtual computer. Learn more about the computer tool.


Hide properties
display_height
integer

The height of the computer display.

display_width
integer

The width of the computer display.

environment
string

The type of computer environment to control.

type
string

The type of the computer use tool. Always computer_use_preview.

MCP tool
object
Give the model access to additional tools via remote Model Context Protocol (MCP) servers. Learn more about MCP.


Hide properties
server_label
string

A label for this MCP server, used to identify it in tool calls.

server_url
string

The URL for the MCP server.

type
string

The type of the MCP tool. Always mcp.

allowed_tools
array or object

List of allowed tool names or a filter object.


Show possible types
headers
object or null

Optional HTTP headers to send to the MCP server. Use for authentication or other purposes.

require_approval
object or string

Specify which of the MCP server's tools require approval.


Show possible types
Code interpreter
object
A tool that runs Python code to help generate a response to a prompt.


Hide properties
container
string or object

The code interpreter container. Can be a container ID or an object that specifies uploaded file IDs to make available to your code.


Show possible types
type
string

The type of the code interpreter tool. Always code_interpreter.

Image generation tool
object
A tool that generates images using a model like gpt-image-1.


Hide properties
type
string

The type of the image generation tool. Always image_generation.

background
string

Background type for the generated image. One of transparent, opaque, or auto. Default: auto.

input_image_mask
object

Optional mask for inpainting. Contains image_url (string, optional) and file_id (string, optional).


Show properties
model
string

The image generation model to use. Default: gpt-image-1.

moderation
string

Moderation level for the generated image. Default: auto.

output_compression
integer

Compression level for the output image. Default: 100.

output_format
string

The output format of the generated image. One of png, webp, or jpeg. Default: png.

partial_images
integer

Number of partial images to generate in streaming mode, from 0 (default value) to 3.

quality
string

The quality of the generated image. One of low, medium, high, or auto. Default: auto.

size
string

The size of the generated image. One of 1024x1024, 1024x1536, 1536x1024, or auto. Default: auto.

Local shell tool
object
A tool that allows the model to execute shell commands in a local environment.


Hide properties
type
string

The type of the local shell tool. Always local_shell.

top_p
number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

background
boolean or null

Whether to run the model response in the background. Learn more.

max_output_tokens
integer or null

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.

output_text
string or null

SDK Only
SDK-only convenience property that contains the aggregated text output from all output_text items in the output array, if any are present. Supported in the Python and JavaScript SDKs.

previous_response_id
string or null

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about conversation state.

reasoning
object or null

o-series models only

Configuration options for reasoning models.


Hide properties
effort
string or null

o-series models only

Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

generate_summary
Deprecated
string or null

Deprecated: use summary instead.

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

summary
string or null

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

service_tier
string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.
When not set, the default behavior is 'auto'.
When this parameter is set, the response body will include the service_tier utilized.

status
string

The status of the response generation. One of completed, failed, in_progress, cancelled, queued, or incomplete.

text
object

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

Text inputs and outputs
Structured Outputs

Hide properties
format
object

An object specifying the format that the model must output.

Configuring { "type": "json_schema" } enables Structured Outputs, which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

The default format is { "type": "text" } with no additional options.

Not recommended for gpt-4o and newer models:

Setting to { "type": "json_object" } enables the older JSON mode, which ensures the message the model generates is valid JSON. Using json_schema is preferred for models that support it.


Hide possible types
Text
object
Default response format. Used to generate text responses.


Show properties
JSON schema
object
JSON Schema response format. Used to generate structured JSON responses. Learn more about Structured Outputs.


Show properties
JSON object
object
JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.


Show properties
truncation
string or null

The truncation strategy to use for the model response.

auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
disabled (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.
usage
object

Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.


Hide properties
input_tokens
integer

The number of input tokens.

input_tokens_details
object

A detailed breakdown of the input tokens.


Hide properties
cached_tokens
integer

The number of tokens that were retrieved from the cache. More on prompt caching.

output_tokens
integer

The number of output tokens.

output_tokens_details
object

A detailed breakdown of the output tokens.


Hide properties
reasoning_tokens
integer

The number of reasoning tokens.

total_tokens
integer

The total number of tokens used.

user
string

A stable identifier for your end-users. Used to boost cache hit rates by better bucketing similar requests and to help OpenAI detect and prevent abuse. Learn more.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.incomplete.

OBJECT response.incomplete
{
  "type": "response.incomplete",
  "response": {
    "id": "resp_123",
    "object": "response",
    "created_at": 1740855869,
    "status": "incomplete",
    "error": null, 
    "incomplete_details": {
      "reason": "max_tokens"
    },
    "instructions": null,
    "max_output_tokens": null,
    "model": "gpt-4o-mini-2024-07-18",
    "output": [],
    "previous_response_id": null,
    "reasoning_effort": null,
    "store": false,
    "temperature": 1,
    "text": {
      "format": {
        "type": "text"
      }
    },
    "tool_choice": "auto",
    "tools": [],
    "top_p": 1,
    "truncation": "disabled",
    "usage": null,
    "user": null,
    "metadata": {}
  },
  "sequence_number": 1
}
response.output_item.added
Emitted when a new output item is added.

item
object

The output item that was added.


Hide possible types
Output message
object
An output message from the model.


Hide properties
content
array

The content of the output message.


Show possible types
id
string

The unique ID of the output message.

role
string

The role of the output message. Always assistant.

status
string

The status of the message input. One of in_progress, completed, or incomplete. Populated when input items are returned via API.

type
string

The type of the output message. Always message.

File search tool call
object
The results of a file search tool call. See the file search guide for more information.


Hide properties
id
string

The unique ID of the file search tool call.

queries
array

The queries used to search for files.

status
string

The status of the file search tool call. One of in_progress, searching, incomplete or failed,

type
string

The type of the file search tool call. Always file_search_call.

results
array or null

The results of the file search tool call.


Show properties
Function tool call
object
A tool call to run a function. See the function calling guide for more information.


Hide properties
arguments
string

A JSON string of the arguments to pass to the function.

call_id
string

The unique ID of the function tool call generated by the model.

name
string

The name of the function to run.

type
string

The type of the function tool call. Always function_call.

id
string

The unique ID of the function tool call.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Web search tool call
object
The results of a web search tool call. See the web search guide for more information.


Hide properties
id
string

The unique ID of the web search tool call.

status
string

The status of the web search tool call.

type
string

The type of the web search tool call. Always web_search_call.

Computer tool call
object
A tool call to a computer use tool. See the computer use guide for more information.


Hide properties
action
object


Show possible types
call_id
string

An identifier used when responding to the tool call with output.

id
string

The unique ID of the computer call.

pending_safety_checks
array

The pending safety checks for the computer call.


Show properties
status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

type
string

The type of the computer call. Always computer_call.

Reasoning
object
A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your input to the Responses API for subsequent turns of a conversation if you are manually managing context.


Hide properties
id
string

The unique identifier of the reasoning content.

summary
array

Reasoning text contents.


Show properties
type
string

The type of the object. Always reasoning.

encrypted_content
string or null

The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Image generation call
object
An image generation request made by the model.


Hide properties
id
string

The unique ID of the image generation call.

result
string or null

The generated image encoded in base64.

status
string

The status of the image generation call.

type
string

The type of the image generation call. Always image_generation_call.

Code interpreter tool call
object
A tool call to run code.


Hide properties
code
string

The code to run.

id
string

The unique ID of the code interpreter tool call.

results
array

The results of the code interpreter tool call.


Show possible types
status
string

The status of the code interpreter tool call.

type
string

The type of the code interpreter tool call. Always code_interpreter_call.

container_id
string

The ID of the container used to run the code.

Local shell call
object
A tool call to run a command on the local shell.


Hide properties
action
object

Execute a shell command on the server.


Show properties
call_id
string

The unique ID of the local shell tool call generated by the model.

id
string

The unique ID of the local shell call.

status
string

The status of the local shell call.

type
string

The type of the local shell call. Always local_shell_call.

MCP tool call
object
An invocation of a tool on an MCP server.


Hide properties
arguments
string

A JSON string of the arguments passed to the tool.

id
string

The unique ID of the tool call.

name
string

The name of the tool that was run.

server_label
string

The label of the MCP server running the tool.

type
string

The type of the item. Always mcp_call.

error
string or null

The error from the tool call, if any.

output
string or null

The output from the tool call.

MCP list tools
object
A list of tools available on an MCP server.


Hide properties
id
string

The unique ID of the list.

server_label
string

The label of the MCP server.

tools
array

The tools available on the server.


Show properties
type
string

The type of the item. Always mcp_list_tools.

error
string or null

Error message if the server could not list tools.

MCP approval request
object
A request for human approval of a tool invocation.


Hide properties
arguments
string

A JSON string of arguments for the tool.

id
string

The unique ID of the approval request.

name
string

The name of the tool to run.

server_label
string

The label of the MCP server making the request.

type
string

The type of the item. Always mcp_approval_request.

output_index
integer

The index of the output item that was added.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.output_item.added.

OBJECT response.output_item.added
{
  "type": "response.output_item.added",
  "output_index": 0,
  "item": {
    "id": "msg_123",
    "status": "in_progress",
    "type": "message",
    "role": "assistant",
    "content": []
  },
  "sequence_number": 1
}
response.output_item.done
Emitted when an output item is marked done.

item
object

The output item that was marked done.


Hide possible types
Output message
object
An output message from the model.


Hide properties
content
array

The content of the output message.


Show possible types
id
string

The unique ID of the output message.

role
string

The role of the output message. Always assistant.

status
string

The status of the message input. One of in_progress, completed, or incomplete. Populated when input items are returned via API.

type
string

The type of the output message. Always message.

File search tool call
object
The results of a file search tool call. See the file search guide for more information.


Hide properties
id
string

The unique ID of the file search tool call.

queries
array

The queries used to search for files.

status
string

The status of the file search tool call. One of in_progress, searching, incomplete or failed,

type
string

The type of the file search tool call. Always file_search_call.

results
array or null

The results of the file search tool call.


Show properties
Function tool call
object
A tool call to run a function. See the function calling guide for more information.


Hide properties
arguments
string

A JSON string of the arguments to pass to the function.

call_id
string

The unique ID of the function tool call generated by the model.

name
string

The name of the function to run.

type
string

The type of the function tool call. Always function_call.

id
string

The unique ID of the function tool call.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Web search tool call
object
The results of a web search tool call. See the web search guide for more information.


Hide properties
id
string

The unique ID of the web search tool call.

status
string

The status of the web search tool call.

type
string

The type of the web search tool call. Always web_search_call.

Computer tool call
object
A tool call to a computer use tool. See the computer use guide for more information.


Hide properties
action
object


Show possible types
call_id
string

An identifier used when responding to the tool call with output.

id
string

The unique ID of the computer call.

pending_safety_checks
array

The pending safety checks for the computer call.


Show properties
status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

type
string

The type of the computer call. Always computer_call.

Reasoning
object
A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your input to the Responses API for subsequent turns of a conversation if you are manually managing context.


Hide properties
id
string

The unique identifier of the reasoning content.

summary
array

Reasoning text contents.


Show properties
type
string

The type of the object. Always reasoning.

encrypted_content
string or null

The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Image generation call
object
An image generation request made by the model.


Hide properties
id
string

The unique ID of the image generation call.

result
string or null

The generated image encoded in base64.

status
string

The status of the image generation call.

type
string

The type of the image generation call. Always image_generation_call.

Code interpreter tool call
object
A tool call to run code.


Hide properties
code
string

The code to run.

id
string

The unique ID of the code interpreter tool call.

results
array

The results of the code interpreter tool call.


Show possible types
status
string

The status of the code interpreter tool call.

type
string

The type of the code interpreter tool call. Always code_interpreter_call.

container_id
string

The ID of the container used to run the code.

Local shell call
object
A tool call to run a command on the local shell.


Hide properties
action
object

Execute a shell command on the server.


Show properties
call_id
string

The unique ID of the local shell tool call generated by the model.

id
string

The unique ID of the local shell call.

status
string

The status of the local shell call.

type
string

The type of the local shell call. Always local_shell_call.

MCP tool call
object
An invocation of a tool on an MCP server.


Hide properties
arguments
string

A JSON string of the arguments passed to the tool.

id
string

The unique ID of the tool call.

name
string

The name of the tool that was run.

server_label
string

The label of the MCP server running the tool.

type
string

The type of the item. Always mcp_call.

error
string or null

The error from the tool call, if any.

output
string or null

The output from the tool call.

MCP list tools
object
A list of tools available on an MCP server.


Hide properties
id
string

The unique ID of the list.

server_label
string

The label of the MCP server.

tools
array

The tools available on the server.


Show properties
type
string

The type of the item. Always mcp_list_tools.

error
string or null

Error message if the server could not list tools.

MCP approval request
object
A request for human approval of a tool invocation.


Hide properties
arguments
string

A JSON string of arguments for the tool.

id
string

The unique ID of the approval request.

name
string

The name of the tool to run.

server_label
string

The label of the MCP server making the request.

type
string

The type of the item. Always mcp_approval_request.

output_index
integer

The index of the output item that was marked done.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.output_item.done.

OBJECT response.output_item.done
{
  "type": "response.output_item.done",
  "output_index": 0,
  "item": {
    "id": "msg_123",
    "status": "completed",
    "type": "message",
    "role": "assistant",
    "content": [
      {
        "type": "output_text",
        "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
        "annotations": []
      }
    ]
  },
  "sequence_number": 1
}
response.content_part.added
Emitted when a new content part is added.

content_index
integer

The index of the content part that was added.

item_id
string

The ID of the output item that the content part was added to.

output_index
integer

The index of the output item that the content part was added to.

part
object

The content part that was added.


Hide possible types
Output text
object
A text output from the model.


Hide properties
annotations
array

The annotations of the text output.


Show possible types
text
string

The text output from the model.

type
string

The type of the output text. Always output_text.

logprobs
array


Show properties
Refusal
object
A refusal from the model.


Hide properties
refusal
string

The refusal explanationfrom the model.

type
string

The type of the refusal. Always refusal.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.content_part.added.

OBJECT response.content_part.added
{
  "type": "response.content_part.added",
  "item_id": "msg_123",
  "output_index": 0,
  "content_index": 0,
  "part": {
    "type": "output_text",
    "text": "",
    "annotations": []
  },
  "sequence_number": 1
}
response.content_part.done
Emitted when a content part is done.

content_index
integer

The index of the content part that is done.

item_id
string

The ID of the output item that the content part was added to.

output_index
integer

The index of the output item that the content part was added to.

part
object

The content part that is done.


Hide possible types
Output text
object
A text output from the model.


Hide properties
annotations
array

The annotations of the text output.


Show possible types
text
string

The text output from the model.

type
string

The type of the output text. Always output_text.

logprobs
array


Show properties
Refusal
object
A refusal from the model.


Hide properties
refusal
string

The refusal explanationfrom the model.

type
string

The type of the refusal. Always refusal.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.content_part.done.

OBJECT response.content_part.done
{
  "type": "response.content_part.done",
  "item_id": "msg_123",
  "output_index": 0,
  "content_index": 0,
  "sequence_number": 1,
  "part": {
    "type": "output_text",
    "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
    "annotations": []
  }
}
response.output_text.delta
Emitted when there is an additional text delta.

content_index
integer

The index of the content part that the text delta was added to.

delta
string

The text delta that was added.

item_id
string

The ID of the output item that the text delta was added to.

output_index
integer

The index of the output item that the text delta was added to.

sequence_number
integer

The sequence number for this event.

type
string

The type of the event. Always response.output_text.delta.

OBJECT response.output_text.delta
{
  "type": "response.output_text.delta",
  "item_id": "msg_123",
  "output_index": 0,
  "content_index": 0,
  "delta": "In",
  "sequence_number": 1
}
response.output_text.done
Emitted when text content is finalized.

content_index
integer

The index of the content part that the text content is finalized.

item_id
string

The ID of the output item that the text content is finalized.

output_index
integer

The index of the output item that the text content is finalized.

sequence_number
integer

The sequence number for this event.

text
string

The text content that is finalized.

type
string

The type of the event. Always response.output_text.done.

OBJECT response.output_text.done
{
  "type": "response.output_text.done",
  "item_id": "msg_123",
  "output_index": 0,
  "content_index": 0,
  "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
  "sequence_number": 1
}
response.refusal.delta
Emitted when there is a partial refusal text.

content_index
integer

The index of the content part that the refusal text is added to.

delta
string

The refusal text that is added.

item_id
string

The ID of the output item that the refusal text is added to.

output_index
integer

The index of the output item that the refusal text is added to.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.refusal.delta.

OBJECT response.refusal.delta
{
  "type": "response.refusal.delta",
  "item_id": "msg_123",
  "output_index": 0,
  "content_index": 0,
  "delta": "refusal text so far",
  "sequence_number": 1
}
response.refusal.done
Emitted when refusal text is finalized.

content_index
integer

The index of the content part that the refusal text is finalized.

item_id
string

The ID of the output item that the refusal text is finalized.

output_index
integer

The index of the output item that the refusal text is finalized.

refusal
string

The refusal text that is finalized.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.refusal.done.

OBJECT response.refusal.done
{
  "type": "response.refusal.done",
  "item_id": "item-abc",
  "output_index": 1,
  "content_index": 2,
  "refusal": "final refusal text",
  "sequence_number": 1
}
response.function_call_arguments.delta
Emitted when there is a partial function-call arguments delta.

delta
string

The function-call arguments delta that is added.

item_id
string

The ID of the output item that the function-call arguments delta is added to.

output_index
integer

The index of the output item that the function-call arguments delta is added to.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.function_call_arguments.delta.

OBJECT response.function_call_arguments.delta
{
  "type": "response.function_call_arguments.delta",
  "item_id": "item-abc",
  "output_index": 0,
  "delta": "{ \"arg\":"
  "sequence_number": 1
}
response.function_call_arguments.done
Emitted when function-call arguments are finalized.

arguments
string

The function-call arguments.

item_id
string

The ID of the item.

output_index
integer

The index of the output item.

sequence_number
integer

The sequence number of this event.

type
string

OBJECT response.function_call_arguments.done
{
  "type": "response.function_call_arguments.done",
  "item_id": "item-abc",
  "output_index": 1,
  "arguments": "{ \"arg\": 123 }",
  "sequence_number": 1
}
response.file_search_call.in_progress
Emitted when a file search call is initiated.

item_id
string

The ID of the output item that the file search call is initiated.

output_index
integer

The index of the output item that the file search call is initiated.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.file_search_call.in_progress.

OBJECT response.file_search_call.in_progress
{
  "type": "response.file_search_call.in_progress",
  "output_index": 0,
  "item_id": "fs_123",
  "sequence_number": 1
}
response.file_search_call.searching
Emitted when a file search is currently searching.

item_id
string

The ID of the output item that the file search call is initiated.

output_index
integer

The index of the output item that the file search call is searching.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.file_search_call.searching.

OBJECT response.file_search_call.searching
{
  "type": "response.file_search_call.searching",
  "output_index": 0,
  "item_id": "fs_123",
  "sequence_number": 1
}
response.file_search_call.completed
Emitted when a file search call is completed (results found).

item_id
string

The ID of the output item that the file search call is initiated.

output_index
integer

The index of the output item that the file search call is initiated.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always response.file_search_call.completed.

OBJECT response.file_search_call.completed
{
  "type": "response.file_search_call.completed",
  "output_index": 0,
  "item_id": "fs_123",
  "sequence_number": 1
}
response.web_search_call.in_progress
Emitted when a web search call is initiated.

item_id
string

Unique ID for the output item associated with the web search call.

output_index
integer

The index of the output item that the web search call is associated with.

sequence_number
integer

The sequence number of the web search call being processed.

type
string

The type of the event. Always response.web_search_call.in_progress.

OBJECT response.web_search_call.in_progress
{
  "type": "response.web_search_call.in_progress",
  "output_index": 0,
  "item_id": "ws_123",
  "sequence_number": 0
}
response.web_search_call.searching
Emitted when a web search call is executing.

item_id
string

Unique ID for the output item associated with the web search call.

output_index
integer

The index of the output item that the web search call is associated with.

sequence_number
integer

The sequence number of the web search call being processed.

type
string

The type of the event. Always response.web_search_call.searching.

OBJECT response.web_search_call.searching
{
  "type": "response.web_search_call.searching",
  "output_index": 0,
  "item_id": "ws_123",
  "sequence_number": 0
}
response.web_search_call.completed
Emitted when a web search call is completed.

item_id
string

Unique ID for the output item associated with the web search call.

output_index
integer

The index of the output item that the web search call is associated with.

sequence_number
integer

The sequence number of the web search call being processed.

type
string

The type of the event. Always response.web_search_call.completed.

OBJECT response.web_search_call.completed
{
  "type": "response.web_search_call.completed",
  "output_index": 0,
  "item_id": "ws_123",
  "sequence_number": 0
}
response.reasoning_summary_part.added
Emitted when a new reasoning summary part is added.

item_id
string

The ID of the item this summary part is associated with.

output_index
integer

The index of the output item this summary part is associated with.

part
object

The summary part that was added.


Hide properties
text
string

The text of the summary part.

type
string

The type of the summary part. Always summary_text.

sequence_number
integer

The sequence number of this event.

summary_index
integer

The index of the summary part within the reasoning summary.

type
string

The type of the event. Always response.reasoning_summary_part.added.

OBJECT response.reasoning_summary_part.added
{
  "type": "response.reasoning_summary_part.added",
  "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
  "output_index": 0,
  "summary_index": 0,
  "part": {
    "type": "summary_text",
    "text": ""
  },
  "sequence_number": 1
}
response.reasoning_summary_part.done
Emitted when a reasoning summary part is completed.

item_id
string

The ID of the item this summary part is associated with.

output_index
integer

The index of the output item this summary part is associated with.

part
object

The completed summary part.


Hide properties
text
string

The text of the summary part.

type
string

The type of the summary part. Always summary_text.

sequence_number
integer

The sequence number of this event.

summary_index
integer

The index of the summary part within the reasoning summary.

type
string

The type of the event. Always response.reasoning_summary_part.done.

OBJECT response.reasoning_summary_part.done
{
  "type": "response.reasoning_summary_part.done",
  "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
  "output_index": 0,
  "summary_index": 0,
  "part": {
    "type": "summary_text",
    "text": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!"
  },
  "sequence_number": 1
}
response.reasoning_summary_text.delta
Emitted when a delta is added to a reasoning summary text.

delta
string

The text delta that was added to the summary.

item_id
string

The ID of the item this summary text delta is associated with.

output_index
integer

The index of the output item this summary text delta is associated with.

sequence_number
integer

The sequence number of this event.

summary_index
integer

The index of the summary part within the reasoning summary.

type
string

The type of the event. Always response.reasoning_summary_text.delta.

OBJECT response.reasoning_summary_text.delta
{
  "type": "response.reasoning_summary_text.delta",
  "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
  "output_index": 0,
  "summary_index": 0,
  "delta": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!",
  "sequence_number": 1
}
response.reasoning_summary_text.done
Emitted when a reasoning summary text is completed.

item_id
string

The ID of the item this summary text is associated with.

output_index
integer

The index of the output item this summary text is associated with.

sequence_number
integer

The sequence number of this event.

summary_index
integer

The index of the summary part within the reasoning summary.

text
string

The full text of the completed reasoning summary.

type
string

The type of the event. Always response.reasoning_summary_text.done.

OBJECT response.reasoning_summary_text.done
{
  "type": "response.reasoning_summary_text.done",
  "item_id": "rs_6806bfca0b2481918a5748308061a2600d3ce51bdffd5476",
  "output_index": 0,
  "summary_index": 0,
  "text": "**Responding to a greeting**\n\nThe user just said, \"Hello!\" So, it seems I need to engage. I'll greet them back and offer help since they're looking to chat. I could say something like, \"Hello! How can I assist you today?\" That feels friendly and open. They didn't ask a specific question, so this approach will work well for starting a conversation. Let's see where it goes from there!",
  "sequence_number": 1
}
response.image_generation_call.completed
Emitted when an image generation tool call has completed and the final image is available.

item_id
string

The unique identifier of the image generation item being processed.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.image_generation_call.completed'.

OBJECT response.image_generation_call.completed
{
  "type": "response.image_generation_call.completed",
  "output_index": 0,
  "item_id": "item-123",
  "sequence_number": 1
}
response.image_generation_call.generating
Emitted when an image generation tool call is actively generating an image (intermediate state).

item_id
string

The unique identifier of the image generation item being processed.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of the image generation item being processed.

type
string

The type of the event. Always 'response.image_generation_call.generating'.

OBJECT response.image_generation_call.generating
{
  "type": "response.image_generation_call.generating",
  "output_index": 0,
  "item_id": "item-123",
  "sequence_number": 0
}
response.image_generation_call.in_progress
Emitted when an image generation tool call is in progress.

item_id
string

The unique identifier of the image generation item being processed.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of the image generation item being processed.

type
string

The type of the event. Always 'response.image_generation_call.in_progress'.

OBJECT response.image_generation_call.in_progress
{
  "type": "response.image_generation_call.in_progress",
  "output_index": 0,
  "item_id": "item-123",
  "sequence_number": 0
}
response.image_generation_call.partial_image
Emitted when a partial image is available during image generation streaming.

item_id
string

The unique identifier of the image generation item being processed.

output_index
integer

The index of the output item in the response's output array.

partial_image_b64
string

Base64-encoded partial image data, suitable for rendering as an image.

partial_image_index
integer

0-based index for the partial image (backend is 1-based, but this is 0-based for the user).

sequence_number
integer

The sequence number of the image generation item being processed.

type
string

The type of the event. Always 'response.image_generation_call.partial_image'.

OBJECT response.image_generation_call.partial_image
{
  "type": "response.image_generation_call.partial_image",
  "output_index": 0,
  "item_id": "item-123",
  "sequence_number": 0,
  "partial_image_index": 0,
  "partial_image_b64": "..."
}
response.mcp_call.arguments.delta
Emitted when there is a delta (partial update) to the arguments of an MCP tool call.

delta
object

The partial update to the arguments for the MCP tool call.

item_id
string

The unique identifier of the MCP tool call item being processed.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.mcp_call.arguments_delta'.

OBJECT response.mcp_call.arguments.delta
{
  "type": "response.mcp_call.arguments.delta",
  "output_index": 0,
  "item_id": "item-abc",
  "delta": {
    "arg1": "new_value1",
    "arg2": "new_value2"
  },
  "sequence_number": 1
}
response.mcp_call.arguments.done
Emitted when the arguments for an MCP tool call are finalized.

arguments
object

The finalized arguments for the MCP tool call.

item_id
string

The unique identifier of the MCP tool call item being processed.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.mcp_call.arguments_done'.

OBJECT response.mcp_call.arguments.done
{
  "type": "response.mcp_call.arguments.done",
  "output_index": 0,
  "item_id": "item-abc",
  "arguments": {
    "arg1": "value1",
    "arg2": "value2"
  },
  "sequence_number": 1
}
response.mcp_call.completed
Emitted when an MCP tool call has completed successfully.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.mcp_call.completed'.

OBJECT response.mcp_call.completed
{
  "type": "response.mcp_call.completed",
  "sequence_number": 1
}
response.mcp_call.failed
Emitted when an MCP tool call has failed.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.mcp_call.failed'.

OBJECT response.mcp_call.failed
{
  "type": "response.mcp_call.failed",
  "sequence_number": 1
}
response.mcp_call.in_progress
Emitted when an MCP tool call is in progress.

item_id
string

The unique identifier of the MCP tool call item being processed.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.mcp_call.in_progress'.

OBJECT response.mcp_call.in_progress
{
  "type": "response.mcp_call.in_progress",
  "output_index": 0,
  "item_id": "item-abc",
  "sequence_number": 1
}
response.mcp_list_tools.completed
Emitted when the list of available MCP tools has been successfully retrieved.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.mcp_list_tools.completed'.

OBJECT response.mcp_list_tools.completed
{
  "type": "response.mcp_list_tools.completed",
  "sequence_number": 1
}
response.mcp_list_tools.failed
Emitted when the attempt to list available MCP tools has failed.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.mcp_list_tools.failed'.

OBJECT response.mcp_list_tools.failed
{
  "type": "response.mcp_list_tools.failed",
  "sequence_number": 1
}
response.mcp_list_tools.in_progress
Emitted when the system is in the process of retrieving the list of available MCP tools.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.mcp_list_tools.in_progress'.

OBJECT response.mcp_list_tools.in_progress
{
  "type": "response.mcp_list_tools.in_progress",
  "sequence_number": 1
}
response.output_text_annotation.added
Emitted when an annotation is added to output text content.

annotation
object

The annotation object being added. (See annotation schema for details.)

annotation_index
integer

The index of the annotation within the content part.

content_index
integer

The index of the content part within the output item.

item_id
string

The unique identifier of the item to which the annotation is being added.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.output_text_annotation.added'.

OBJECT response.output_text_annotation.added
{
  "type": "response.output_text_annotation.added",
  "item_id": "item-abc",
  "output_index": 0,
  "content_index": 0,
  "annotation_index": 0,
  "annotation": {
    "type": "text_annotation",
    "text": "This is a test annotation",
    "start": 0,
    "end": 10
  },
  "sequence_number": 1
}
response.queued
Emitted when a response is queued and waiting to be processed.

response
object

The full response object that is queued.


Hide properties
created_at
number

Unix timestamp (in seconds) of when this Response was created.

error
object or null

An error object returned when the model fails to generate a Response.


Hide properties
code
string

The error code for the response.

message
string

A human-readable description of the error.

id
string

Unique identifier for this Response.

incomplete_details
object or null

Details about why the response is incomplete.


Hide properties
reason
string

The reason why the response is incomplete.

instructions
string or null

Inserts a system (or developer) message as the first item in the model's context.

When using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

metadata
map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

model
string

Model ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.

object
string

The object type of this resource - always set to response.

output
array

An array of content items generated by the model.

The length and order of items in the output array is dependent on the model's response.
Rather than accessing the first item in the output array and assuming it's an assistant message with the content generated by the model, you might consider using the output_text property where supported in SDKs.

Hide possible types
Output message
object
An output message from the model.


Hide properties
content
array

The content of the output message.


Show possible types
id
string

The unique ID of the output message.

role
string

The role of the output message. Always assistant.

status
string

The status of the message input. One of in_progress, completed, or incomplete. Populated when input items are returned via API.

type
string

The type of the output message. Always message.

File search tool call
object
The results of a file search tool call. See the file search guide for more information.


Hide properties
id
string

The unique ID of the file search tool call.

queries
array

The queries used to search for files.

status
string

The status of the file search tool call. One of in_progress, searching, incomplete or failed,

type
string

The type of the file search tool call. Always file_search_call.

results
array or null

The results of the file search tool call.


Show properties
Function tool call
object
A tool call to run a function. See the function calling guide for more information.


Hide properties
arguments
string

A JSON string of the arguments to pass to the function.

call_id
string

The unique ID of the function tool call generated by the model.

name
string

The name of the function to run.

type
string

The type of the function tool call. Always function_call.

id
string

The unique ID of the function tool call.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Web search tool call
object
The results of a web search tool call. See the web search guide for more information.


Hide properties
id
string

The unique ID of the web search tool call.

status
string

The status of the web search tool call.

type
string

The type of the web search tool call. Always web_search_call.

Computer tool call
object
A tool call to a computer use tool. See the computer use guide for more information.


Hide properties
action
object


Show possible types
call_id
string

An identifier used when responding to the tool call with output.

id
string

The unique ID of the computer call.

pending_safety_checks
array

The pending safety checks for the computer call.


Show properties
status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

type
string

The type of the computer call. Always computer_call.

Reasoning
object
A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your input to the Responses API for subsequent turns of a conversation if you are manually managing context.


Hide properties
id
string

The unique identifier of the reasoning content.

summary
array

Reasoning text contents.


Show properties
type
string

The type of the object. Always reasoning.

encrypted_content
string or null

The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.

status
string

The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Image generation call
object
An image generation request made by the model.


Hide properties
id
string

The unique ID of the image generation call.

result
string or null

The generated image encoded in base64.

status
string

The status of the image generation call.

type
string

The type of the image generation call. Always image_generation_call.

Code interpreter tool call
object
A tool call to run code.


Hide properties
code
string

The code to run.

id
string

The unique ID of the code interpreter tool call.

results
array

The results of the code interpreter tool call.


Show possible types
status
string

The status of the code interpreter tool call.

type
string

The type of the code interpreter tool call. Always code_interpreter_call.

container_id
string

The ID of the container used to run the code.

Local shell call
object
A tool call to run a command on the local shell.


Hide properties
action
object

Execute a shell command on the server.


Show properties
call_id
string

The unique ID of the local shell tool call generated by the model.

id
string

The unique ID of the local shell call.

status
string

The status of the local shell call.

type
string

The type of the local shell call. Always local_shell_call.

MCP tool call
object
An invocation of a tool on an MCP server.


Hide properties
arguments
string

A JSON string of the arguments passed to the tool.

id
string

The unique ID of the tool call.

name
string

The name of the tool that was run.

server_label
string

The label of the MCP server running the tool.

type
string

The type of the item. Always mcp_call.

error
string or null

The error from the tool call, if any.

output
string or null

The output from the tool call.

MCP list tools
object
A list of tools available on an MCP server.


Hide properties
id
string

The unique ID of the list.

server_label
string

The label of the MCP server.

tools
array

The tools available on the server.


Show properties
type
string

The type of the item. Always mcp_list_tools.

error
string or null

Error message if the server could not list tools.

MCP approval request
object
A request for human approval of a tool invocation.


Hide properties
arguments
string

A JSON string of arguments for the tool.

id
string

The unique ID of the approval request.

name
string

The name of the tool to run.

server_label
string

The label of the MCP server making the request.

type
string

The type of the item. Always mcp_approval_request.

parallel_tool_calls
boolean

Whether to allow the model to run tool calls in parallel.

temperature
number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.

tool_choice
string or object

How the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how to specify which tools the model can call.


Hide possible types
Tool choice mode
string
Controls which (if any) tool is called by the model.

none means the model will not call any tool and instead generates a message.

auto means the model can pick between generating a message or calling one or more tools.

required means the model must call one or more tools.

Hosted tool
object
Indicates that the model should use a built-in tool to generate a response. Learn more about built-in tools.


Hide properties
type
string

The type of hosted tool the model should to use. Learn more about built-in tools.

Allowed values are:

file_search
web_search_preview
computer_use_preview
code_interpreter
mcp
image_generation
Function tool
object
Use this option to force the model to call a specific function.


Hide properties
name
string

The name of the function to call.

type
string

For function calling, the type is always function.

tools
array

An array of tools the model may call while generating a response. You can specify which tool to use by setting the tool_choice parameter.

The two categories of tools you can provide the model are:

Built-in tools: Tools that are provided by OpenAI that extend the model's capabilities, like web search or file search. Learn more about built-in tools.
Function calls (custom tools): Functions that are defined by you, enabling the model to call your own code. Learn more about function calling.

Hide possible types
Function
object
Defines a function in your own code the model can choose to call. Learn more about function calling.


Hide properties
name
string

The name of the function to call.

parameters
object

A JSON schema object describing the parameters of the function.

strict
boolean

Whether to enforce strict parameter validation. Default true.

type
string

The type of the function tool. Always function.

description
string

A description of the function. Used by the model to determine whether or not to call the function.

File search
object
A tool that searches for relevant content from uploaded files. Learn more about the file search tool.


Hide properties
type
string

The type of the file search tool. Always file_search.

vector_store_ids
array

The IDs of the vector stores to search.

filters
object

A filter to apply.


Show possible types
max_num_results
integer

The maximum number of results to return. This number should be between 1 and 50 inclusive.

ranking_options
object

Ranking options for search.


Show properties
Web search preview
object
This tool searches the web for relevant results to use in a response. Learn more about the web search tool.


Hide properties
type
string

The type of the web search tool. One of web_search_preview or web_search_preview_2025_03_11.

search_context_size
string

High level guidance for the amount of context window space to use for the search. One of low, medium, or high. medium is the default.

user_location
object

The user's location.


Show properties
Computer use preview
object
A tool that controls a virtual computer. Learn more about the computer tool.


Hide properties
display_height
integer

The height of the computer display.

display_width
integer

The width of the computer display.

environment
string

The type of computer environment to control.

type
string

The type of the computer use tool. Always computer_use_preview.

MCP tool
object
Give the model access to additional tools via remote Model Context Protocol (MCP) servers. Learn more about MCP.


Hide properties
server_label
string

A label for this MCP server, used to identify it in tool calls.

server_url
string

The URL for the MCP server.

type
string

The type of the MCP tool. Always mcp.

allowed_tools
array or object

List of allowed tool names or a filter object.


Show possible types
headers
object or null

Optional HTTP headers to send to the MCP server. Use for authentication or other purposes.

require_approval
object or string

Specify which of the MCP server's tools require approval.


Show possible types
Code interpreter
object
A tool that runs Python code to help generate a response to a prompt.


Hide properties
container
string or object

The code interpreter container. Can be a container ID or an object that specifies uploaded file IDs to make available to your code.


Show possible types
type
string

The type of the code interpreter tool. Always code_interpreter.

Image generation tool
object
A tool that generates images using a model like gpt-image-1.


Hide properties
type
string

The type of the image generation tool. Always image_generation.

background
string

Background type for the generated image. One of transparent, opaque, or auto. Default: auto.

input_image_mask
object

Optional mask for inpainting. Contains image_url (string, optional) and file_id (string, optional).


Show properties
model
string

The image generation model to use. Default: gpt-image-1.

moderation
string

Moderation level for the generated image. Default: auto.

output_compression
integer

Compression level for the output image. Default: 100.

output_format
string

The output format of the generated image. One of png, webp, or jpeg. Default: png.

partial_images
integer

Number of partial images to generate in streaming mode, from 0 (default value) to 3.

quality
string

The quality of the generated image. One of low, medium, high, or auto. Default: auto.

size
string

The size of the generated image. One of 1024x1024, 1024x1536, 1536x1024, or auto. Default: auto.

Local shell tool
object
A tool that allows the model to execute shell commands in a local environment.


Hide properties
type
string

The type of the local shell tool. Always local_shell.

top_p
number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

background
boolean or null

Whether to run the model response in the background. Learn more.

max_output_tokens
integer or null

An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.

output_text
string or null

SDK Only
SDK-only convenience property that contains the aggregated text output from all output_text items in the output array, if any are present. Supported in the Python and JavaScript SDKs.

previous_response_id
string or null

The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about conversation state.

reasoning
object or null

o-series models only

Configuration options for reasoning models.


Hide properties
effort
string or null

o-series models only

Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

generate_summary
Deprecated
string or null

Deprecated: use summary instead.

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

summary
string or null

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

service_tier
string or null

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.
If set to 'flex', the request will be processed with the Flex Processing service tier. Learn more.
When not set, the default behavior is 'auto'.
When this parameter is set, the response body will include the service_tier utilized.

status
string

The status of the response generation. One of completed, failed, in_progress, cancelled, queued, or incomplete.

text
object

Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

Text inputs and outputs
Structured Outputs

Hide properties
format
object

An object specifying the format that the model must output.

Configuring { "type": "json_schema" } enables Structured Outputs, which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

The default format is { "type": "text" } with no additional options.

Not recommended for gpt-4o and newer models:

Setting to { "type": "json_object" } enables the older JSON mode, which ensures the message the model generates is valid JSON. Using json_schema is preferred for models that support it.


Hide possible types
Text
object
Default response format. Used to generate text responses.


Show properties
JSON schema
object
JSON Schema response format. Used to generate structured JSON responses. Learn more about Structured Outputs.


Show properties
JSON object
object
JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.


Show properties
truncation
string or null

The truncation strategy to use for the model response.

auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.
disabled (default): If a model response will exceed the context window size for a model, the request will fail with a 400 error.
usage
object

Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.


Hide properties
input_tokens
integer

The number of input tokens.

input_tokens_details
object

A detailed breakdown of the input tokens.


Hide properties
cached_tokens
integer

The number of tokens that were retrieved from the cache. More on prompt caching.

output_tokens
integer

The number of output tokens.

output_tokens_details
object

A detailed breakdown of the output tokens.


Hide properties
reasoning_tokens
integer

The number of reasoning tokens.

total_tokens
integer

The total number of tokens used.

user
string

A stable identifier for your end-users. Used to boost cache hit rates by better bucketing similar requests and to help OpenAI detect and prevent abuse. Learn more.

sequence_number
integer

The sequence number for this event.

type
string

The type of the event. Always 'response.queued'.

OBJECT response.queued
{
  "type": "response.queued",
  "response": {
    "id": "res_123",
    "status": "queued",
    "created_at": "2021-01-01T00:00:00Z",
    "updated_at": "2021-01-01T00:00:00Z"
  },
  "sequence_number": 1
}
response.reasoning.delta
Emitted when there is a delta (partial update) to the reasoning content.

content_index
integer

The index of the reasoning content part within the output item.

delta
object

The partial update to the reasoning content.

item_id
string

The unique identifier of the item for which reasoning is being updated.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always 'response.reasoning.delta'.

OBJECT response.reasoning.delta
{
  "type": "response.reasoning.delta",
  "item_id": "item-abc",
  "output_index": 0,
  "content_index": 0,
  "delta": {
    "text": "This is a test delta"
  },
  "sequence_number": 1
}
response.reasoning.done
Emitted when the reasoning content is finalized for an item.

content_index
integer

The index of the reasoning content part within the output item.

item_id
string

The unique identifier of the item for which reasoning is finalized.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of this event.

text
string

The finalized reasoning text.

type
string

The type of the event. Always 'response.reasoning.done'.

OBJECT response.reasoning.done
{
  "type": "response.reasoning.done",
  "item_id": "item-abc",
  "output_index": 0,
  "content_index": 0,
  "text": "This is a test reasoning",
  "sequence_number": 1
}
response.reasoning_summary.delta
Emitted when there is a delta (partial update) to the reasoning summary content.

delta
object

The partial update to the reasoning summary content.

item_id
string

The unique identifier of the item for which the reasoning summary is being updated.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of this event.

summary_index
integer

The index of the summary part within the output item.

type
string

The type of the event. Always 'response.reasoning_summary.delta'.

OBJECT response.reasoning_summary.delta
{
  "type": "response.reasoning_summary.delta",
  "item_id": "item-abc",
  "output_index": 0,
  "summary_index": 0,
  "delta": {
    "text": "delta text"
  },
  "sequence_number": 1
}
response.reasoning_summary.done
Emitted when the reasoning summary content is finalized for an item.

item_id
string

The unique identifier of the item for which the reasoning summary is finalized.

output_index
integer

The index of the output item in the response's output array.

sequence_number
integer

The sequence number of this event.

summary_index
integer

The index of the summary part within the output item.

text
string

The finalized reasoning summary text.

type
string

The type of the event. Always 'response.reasoning_summary.done'.

error
Emitted when an error occurs.

code
string or null

The error code.

message
string

The error message.

param
string or null

The error parameter.

sequence_number
integer

The sequence number of this event.

type
string

The type of the event. Always error.
