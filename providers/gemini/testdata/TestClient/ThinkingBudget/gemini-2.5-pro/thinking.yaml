---
version: 2
interactions:
- id: 0
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 202
    host: generativelanguage.googleapis.com
    body: "{\"contents\":[{\"role\":\"user\",\"parts\":[{\"text\":\"Say hello. Do not emit other words.\"}]}],\"generationConfig\":{\"responseModalities\":[\"TEXT\"],\"thinkingConfig\":{\"includeThoughts\":true,\"thinkingBudget\":512}}}\n"
    headers:
      Content-Type:
      - application/json; charset=utf-8
    url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent
    method: POST
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: -1
    uncompressed: true
    body: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"**My thought process in fulfilling this request:**\\n\\nOkay, the user wants me to say \\\"hello.\\\" That's simple enough on the surface, but there are constraints to consider. The core instruction is clear: \\\"Say hello.\\\" However, the critical negative constraint is \\\"Do not emit other words.\\\" This means I need to be *very* precise.\\n\\nThe obvious response is \\\"Hello\\\", but I have to be completely sure. Is a period a \\\"word\\\"? The instruction is to avoid emitting *other words*, not *other characters*. Punctuation doesn't count as a \\\"word\\\" in this context. But to be absolutely safe and to adhere to the strictest interpretation, let's keep it just the single word. \\\"Hello.\\\" would satisfy the primary goal and technically avoid the constraint as punctuation is not a \\\"word\\\". However, omitting the punctuation is the most cautious and direct response. The safest and most literal interpretation is simply the word, which is \\\"Hello.\\\"\\n\\nLet's deliver that.\\n\",\n            \"thought\": true\n          },\n          {\n            \"text\": \"Hello.\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 10,\n    \"candidatesTokenCount\": 2,\n    \"totalTokenCount\": 250,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 10\n      }\n    ],\n    \"thoughtsTokenCount\": 238\n  },\n  \"modelVersion\": \"gemini-2.5-pro\",\n  \"responseId\": \"FvKxaPDuNNOs1MkP0a6MwAE\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=4787
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-Xss-Protection:
      - "0"
    status: 200 OK
    code: 200
    duration: 4.797s
