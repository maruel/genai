---
version: 2
interactions:
- id: 0
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 291
    host: generativelanguage.googleapis.com
    body: "{\"contents\":[{\"role\":\"user\",\"parts\":[{\"text\":\"The capital of Quackiland is Quack. The Big Canard Statue is located in Quack.\"},{\"text\":\"What is the capital of Quackiland?\"}]}],\"generationConfig\":{\"responseModalities\":[\"TEXT\"],\"thinkingConfig\":{\"includeThoughts\":true,\"thinkingBudget\":512}}}\n"
    headers:
      Content-Type:
      - application/json; charset=utf-8
    url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent
    method: POST
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: -1
    uncompressed: true
    body: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"**My Analytical Approach to Identifying the Capital of Quackiland**\\n\\nOkay, so the user's asking for the capital of Quackiland, which is pretty straightforward. My first instinct is to zero in on the key information: \\\"capital of Quackiland.\\\" I'm an expert in this type of data extraction, so my mind immediately begins scanning the text for that specific phrase or any close variations. It's a quick process, a kind of automated filtering.\\n\\nWithin a split second, I locate the crucial sentence: \\\"The capital of Quackiland is Quack.\\\" Ah, there it is! Now it's simply a matter of extracting the answer. In this case, \\\"Quack\\\" is the extracted value.\\n\\nWith that, I'm ready to provide a direct and concise response, informing the user that \\\"Quack\\\" is indeed the capital of Quackiland. That's the most efficient way to handle this request and, frankly, the only way I'd consider approaching it.\\n\",\n            \"thought\": true\n          },\n          {\n            \"text\": \"The capital of Quackiland is **Quack**.\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 31,\n    \"candidatesTokenCount\": 11,\n    \"totalTokenCount\": 150,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 31\n      }\n    ],\n    \"thoughtsTokenCount\": 108\n  },\n  \"modelVersion\": \"gemini-2.5-flash\",\n  \"responseId\": \"ePiyaJrdEbq9_uMPqNzIuQY\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=2059
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-Xss-Protection:
      - "0"
    status: 200 OK
    code: 200
    duration: 2.066s
