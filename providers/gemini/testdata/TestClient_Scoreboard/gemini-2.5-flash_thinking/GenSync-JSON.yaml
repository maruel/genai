---
version: 2
interactions:
    - id: 0
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 331
        host: generativelanguage.googleapis.com
        body: |
            {"contents":[{"role":"user","parts":[{"text":"Is a banana a fruit? Do not include an explanation. Reply ONLY as JSON according to the provided schema: {\"is_fruit\": bool}."}]}],"generationConfig":{"responseMimeType":"application/json","responseModalities":["TEXT"],"thinkingConfig":{"includeThoughts":true,"thinkingBudget":512}}}
        headers:
            Content-Type:
                - application/json; charset=utf-8
        url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent
        method: POST
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        content_length: -1
        uncompressed: true
        body: |
            {
              "candidates": [
                {
                  "content": {
                    "parts": [
                      {
                        "text": "**Determining the Fruit Status of a Banana**\n\nOkay, I've got a straightforward request: determine if a banana is a fruit. The instruction is clear â€“ just provide a boolean value as the answer, specifically keyed as \"is_fruit\" within a JSON structure. And, of course, no extraneous explanation. Given my understanding of botany, I know a banana unequivocally qualifies as a fruit. Therefore, the JSON response should be `{\"is_fruit\": true}`.\n",
                        "thought": true
                      },
                      {
                        "text": "{\n  \"is_fruit\": true\n}"
                      }
                    ],
                    "role": "model"
                  },
                  "finishReason": "STOP",
                  "index": 0
                }
              ],
              "usageMetadata": {
                "promptTokenCount": 30,
                "candidatesTokenCount": 11,
                "totalTokenCount": 127,
                "promptTokensDetails": [
                  {
                    "modality": "TEXT",
                    "tokenCount": 30
                  }
                ],
                "thoughtsTokenCount": 86
              },
              "modelVersion": "gemini-2.5-flash",
              "responseId": "g12FaPqhFf2OjMcPgdPP6Qo"
            }
        headers:
            Alt-Svc:
                - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
            Content-Type:
                - application/json; charset=UTF-8
            Server:
                - scaffolding on HTTPServer2
            Server-Timing:
                - gfet4t7; dur=1455
            Vary:
                - Origin
                - X-Origin
                - Referer
            X-Content-Type-Options:
                - nosniff
            X-Frame-Options:
                - SAMEORIGIN
            X-Xss-Protection:
                - "0"
        status: 200 OK
        code: 200
        duration: 1.465s
