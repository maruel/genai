---
version: 2
interactions:
    - id: 0
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 0
        host: 127.0.0.1
        headers:
            Content-Type:
                - application/json; charset=utf-8
        url: http://127.0.0.1/v1/models
        method: GET
      response:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 604
        body: '{"models":[{"name":"gemma-3-4b-it-Q4_K_M.gguf","model":"gemma-3-4b-it-Q4_K_M.gguf","modified_at":"","size":"","digest":"","type":"model","description":"","tags":[""],"capabilities":["completion","multimodal"],"parameters":"","details":{"parent_model":"","format":"gguf","family":"","families":[""],"parameter_size":"","quantization_level":""}}],"object":"list","data":[{"id":"gemma-3-4b-it-Q4_K_M.gguf","aliases":[],"tags":[],"object":"model","created":1772373210,"owned_by":"llamacpp","meta":{"vocab_type":1,"n_vocab":262144,"n_ctx_train":131072,"n_embd":2560,"n_params":3880099328,"size":2483218432}}]}'
        headers:
            Access-Control-Allow-Origin:
                - ""
            Content-Length:
                - "604"
            Content-Type:
                - application/json; charset=utf-8
            Keep-Alive:
                - timeout=5, max=100
            Server:
                - llama.cpp
        status: 200 OK
        code: 200
        duration: 0s
