{
  "warnings": [
    "No model supports \"required\" tool calling, which hinders the quality of tool calling everywhere.",
    "Tool calling is solid with llama 3.3 70B quantized in FP8 (-Turbo) but is flaky in more recent models.",
    "Suffix \"-Turbo\" means FP8 quantization.",
    "Suffix \"-Lite\" means INT4 quantization.",
    "Suffix \"-Free\" has lower rate limits."
  ],
  "country": "US",
  "dashboardURL": "https://api.together.ai/settings/billing",
  "scenarios": [
    {
      "models": [
        "Qwen/Qwen3-235B-A22B-Thinking-2507"
      ],
      "sota": true,
      "reason": true,
      "reasoningTokenEnd": "\u003c/think\u003e",
      "in": {
        "image": {
          "inline": true,
          "supportedFormats": [
            "image/jpeg"
          ]
        },
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "flaky",
        "seed": true,
        "tools": "flaky",
        "toolCallRequired": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "models": [
        "black-forest-labs/FLUX.2-pro"
      ],
      "sota": true,
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "image": {
          "url": true,
          "supportedFormats": [
            "image/jpeg"
          ]
        }
      },
      "GenSync": {
        "seed": true
      }
    },
    {
      "models": [
        "Qwen/Qwen3-235B-A22B-fp8-tput"
      ],
      "good": true,
      "reason": true,
      "reasoningTokenStart": "\u003cthink\u003e",
      "reasoningTokenEnd": "\u003c/think\u003e",
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "flaky",
        "seed": true,
        "tools": "flaky",
        "toolsIndecisive": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "models": [
        "black-forest-labs/FLUX.2-dev"
      ],
      "good": true,
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "image": {
          "url": true,
          "supportedFormats": [
            "image/jpeg"
          ]
        }
      },
      "GenSync": {
        "seed": true
      }
    },
    {
      "comments": "TogetherAI has broken reasoning parsing during tool call and JSON output",
      "models": [
        "openai/gpt-oss-20b"
      ],
      "cheap": true,
      "reason": true,
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "flaky",
        "toolsBiased": "flaky",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "flaky",
        "seed": true,
        "tools": "flaky",
        "toolsIndecisive": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true
      }
    },
    {
      "models": [
        "black-forest-labs/FLUX.1-schnell"
      ],
      "cheap": true,
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "image": {
          "url": true,
          "supportedFormats": [
            "image/jpeg"
          ]
        }
      },
      "GenSync": {
        "seed": true
      }
    },
    {
      "models": [
        "Qwen/Qwen3-Next-80B-A3B-Thinking"
      ],
      "reason": true,
      "reasoningTokenStart": "\u003cthink\u003e",
      "reasoningTokenEnd": "\u003c/think\u003e",
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "flaky",
        "toolsBiased": "flaky",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "flaky",
        "seed": true,
        "tools": "flaky",
        "toolsIndecisive": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "models": [
        "moonshotai/Kimi-K2-Thinking"
      ],
      "reason": true,
      "in": {
        "image": {
          "url": true,
          "supportedFormats": [
            "image/jpeg"
          ]
        },
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "flaky",
        "toolsIndecisive": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "comments": "TogetherAI has broken reasoning parsing during tool call and JSON output",
      "models": [
        "openai/gpt-oss-120b"
      ],
      "reason": true,
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "true",
        "json": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "flaky",
        "seed": true,
        "tools": "flaky",
        "json": true,
        "maxTokens": true
      }
    },
    {
      "models": [
        "zai-org/GLM-4.6"
      ],
      "reason": true,
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "flaky",
        "toolsIndecisive": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "models": [
        "Qwen/Qwen3-235B-A22B-Instruct-2507-tput"
      ],
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "flaky",
        "seed": true,
        "tools": "flaky",
        "toolsIndecisive": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "models": [
        "Qwen/Qwen3-Next-80B-A3B-Instruct"
      ],
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "flaky",
        "toolsBiased": "true",
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "flaky",
        "toolsBiased": "true",
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "models": [
        "Qwen/Qwen3-VL-32B-Instruct"
      ],
      "in": {
        "image": {
          "inline": true,
          "url": true,
          "supportedFormats": [
            "image/gif",
            "image/jpeg",
            "image/png",
            "image/webp"
          ]
        },
        "text": {
          "inline": true
        },
        "video": {
          "inline": true,
          "url": true,
          "supportedFormats": [
            "video/mp4",
            "video/webm"
          ]
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "models": [
        "black-forest-labs/FLUX.2-flex"
      ],
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "image": {
          "url": true,
          "supportedFormats": [
            "image/jpeg"
          ]
        }
      },
      "GenSync": {
        "seed": true
      }
    },
    {
      "models": [
        "deepcogito/cogito-v2-1-671b"
      ],
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "models": [
        "essentialai/rnj-1-instruct"
      ],
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "flaky",
        "toolsBiased": "true",
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "flaky",
        "toolsBiased": "true",
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "models": [
        "moonshotai/Kimi-K2-Instruct-0905"
      ],
      "in": {
        "image": {
          "inline": true,
          "url": true,
          "supportedFormats": [
            "image/jpeg",
            "image/png"
          ]
        },
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "flaky",
        "toolsIndecisive": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "comments": "Untested",
      "models": [
        "zai-org/GLM-4.5-Air-FP8"
      ],
      "reason": true
    },
    {
      "comments": "Untested",
      "models": [
        "Alibaba-NLP/gte-modernbert-base",
        "BAAI/bge-base-en-v1.5",
        "BAAI/bge-large-en-v1.5",
        "ByteDance/Seedance-1.0-lite",
        "ByteDance/Seedance-1.0-pro",
        "Meta-Llama/Llama-Guard-7b",
        "Qwen/Qwen2.5-72B-Instruct-Turbo",
        "Qwen/Qwen2.5-7B-Instruct-Turbo",
        "Qwen/Qwen2.5-VL-72B-Instruct",
        "Salesforce/Llama-Rank-V1",
        "ServiceNow-AI/Apriel-1.5-15b-Thinker",
        "ServiceNow-AI/Apriel-1.6-15b-Thinker",
        "Virtue-AI/VirtueGuard-Text-Lite",
        "Wan-AI/Wan2.2-I2V-A14B",
        "Wan-AI/Wan2.2-T2V-A14B",
        "arcee-ai/trinity-mini",
        "arize-ai/qwen-2-1.5b-instruct",
        "black-forest-labs/FLUX.1-dev-lora",
        "black-forest-labs/FLUX.1-kontext-dev",
        "black-forest-labs/FLUX.1-kontext-max",
        "black-forest-labs/FLUX.1-kontext-pro",
        "black-forest-labs/FLUX.1-krea-dev",
        "black-forest-labs/FLUX.1-pro",
        "black-forest-labs/FLUX.1.1-pro",
        "canopylabs/orpheus-3b-0.1-ft",
        "cartesia/sonic",
        "cartesia/sonic-2",
        "deepcogito/cogito-v2-preview-llama-109B-MoE",
        "deepcogito/cogito-v2-preview-llama-405B",
        "deepcogito/cogito-v2-preview-llama-70B",
        "deepseek-ai/DeepSeek-R1",
        "deepseek-ai/DeepSeek-R1-0528-tput",
        "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "deepseek-ai/DeepSeek-V3",
        "google/gemma-3n-E4B-it",
        "google/veo-2.0",
        "google/veo-3.0",
        "google/veo-3.0-audio",
        "google/veo-3.0-fast",
        "google/veo-3.0-fast-audio",
        "hexgrad/Kokoro-82M",
        "intfloat/multilingual-e5-large-instruct",
        "kwaivgI/kling-1.6-pro",
        "kwaivgI/kling-1.6-standard",
        "kwaivgI/kling-2.0-master",
        "kwaivgI/kling-2.1-master",
        "kwaivgI/kling-2.1-pro",
        "kwaivgI/kling-2.1-standard",
        "marin-community/marin-8b-instruct",
        "mercor/cwm",
        "meta-llama/Llama-3-70b-chat-hf",
        "meta-llama/Llama-3-70b-hf",
        "meta-llama/Llama-3.2-3B-Instruct-Turbo",
        "meta-llama/Llama-3.3-70B-Instruct-Turbo",
        "meta-llama/Llama-Guard-3-11B-Vision-Turbo",
        "meta-llama/Llama-Guard-4-12B",
        "meta-llama/LlamaGuard-2-8b",
        "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3-8B-Instruct-Lite",
        "meta-llama/Meta-Llama-3.1-405B-Instruct-Lite-Pro",
        "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "meta-llama/Meta-Llama-Guard-3-8B",
        "minimax/hailuo-02",
        "minimax/video-01-director",
        "mistralai/Ministral-3-14B-Instruct-2512",
        "mistralai/Mistral-7B-Instruct-v0.2",
        "mistralai/Mistral-7B-Instruct-v0.3",
        "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "mixedbread-ai/Mxbai-Rerank-Large-V2",
        "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
        "openai/sora-2",
        "openai/sora-2-pro",
        "openai/whisper-large-v3",
        "pixverse/pixverse-v5",
        "scb10x/scb10x-typhoon-2-1-gemma3-12b",
        "togethercomputer/MoA-1",
        "togethercomputer/MoA-1-Turbo",
        "togethercomputer/Refuel-Llm-V2",
        "togethercomputer/Refuel-Llm-V2-Small",
        "togethercomputer/m2-bert-80M-32k-retrieval",
        "vidu/vidu-2.0",
        "vidu/vidu-q1"
      ]
    },
    {
      "models": [
        "ByteDance-Seed/Seedream-3.0",
        "ByteDance-Seed/Seedream-4.0",
        "HiDream-ai/HiDream-I1-Dev",
        "HiDream-ai/HiDream-I1-Fast",
        "HiDream-ai/HiDream-I1-Full",
        "Lykon/DreamShaper",
        "Qwen/Qwen-Image",
        "Qwen/Qwen2.5-14B-Instruct",
        "Qwen/Qwen2.5-72B-Instruct",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
        "RunDiffusion/Juggernaut-pro-flux",
        "Rundiffusion/Juggernaut-Lightning-Flux",
        "black-forest-labs/FLUX.1-dev",
        "black-forest-labs/FLUX.1-schnell-Free",
        "deepseek-ai/DeepSeek-V3.1",
        "google/flash-image-2.5",
        "google/gemini-3-pro-image",
        "google/imagen-4.0-fast",
        "google/imagen-4.0-preview",
        "google/imagen-4.0-ultra",
        "ideogram/ideogram-3.0",
        "meta-llama/Llama-3.1-405B-Instruct",
        "meta-llama/Llama-3.2-1B-Instruct",
        "meta-llama/Meta-Llama-3-8B-Instruct",
        "meta-llama/Meta-Llama-3.1-70B-Instruct-Reference",
        "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
        "stabilityai/stable-diffusion-3-medium",
        "stabilityai/stable-diffusion-xl-base-1.0"
      ]
    },
    {
      "comments": "Tool calling is flaky because Together.AI only supports tool_choice auto, not required.",
      "models": [
        "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct"
      ]
    },
    {
      "comments": "FinishReason is only broken with JSON.",
      "models": [
        "mistralai/Mistral-Small-24B-Instruct-2501"
      ]
    }
  ]
}
