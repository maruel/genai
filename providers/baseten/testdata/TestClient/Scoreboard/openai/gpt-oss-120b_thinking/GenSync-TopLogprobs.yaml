---
version: 2
interactions:
    - id: 0
      request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 136
        host: inference.baseten.co
        body: |
            {"model":"openai/gpt-oss-120b","messages":[{"role":"user","content":"Say hello. Use only one word."}],"logprobs":true,"top_logprobs":2}
        headers:
            Content-Type:
                - application/json; charset=utf-8
        url: https://inference.baseten.co/v1/chat/completions
        method: POST
      response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        content_length: 82
        body: '{"message":"returning log probs is not supported","type":"Bad Request","code":400}'
        headers:
            Alt-Svc:
                - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
            Content-Length:
                - "82"
            Content-Type:
                - application/json
            Vary:
                - Origin
            Via:
                - 1.1 google
            X-Baseten-Accepted-At:
                - "1771458210944"
        status: 400 Bad Request
        code: 400
        duration: 39ms
