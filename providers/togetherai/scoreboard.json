{
  "warnings": [
    "No model supports \"required\" tool calling, which hinders the quality of tool calling everywhere.",
    "Tool calling is solid with llama 3.3 70B quantized in FP8 (-Turbo) but is flaky in more recent models.",
    "Suffix \"-Turbo\" means FP8 quantization.",
    "Suffix \"-Lite\" means INT4 quantization.",
    "Suffix \"-Free\" has lower rate limits."
  ],
  "country": "US",
  "dashboardURL": "https://api.together.ai/settings/billing",
  "scenarios": [
    {
      "models": [
        "Qwen/Qwen3-235B-A22B-Thinking-2507"
      ],
      "sota": true,
      "reason": true,
      "reasoningTokenStart": "\u003cthink\u003e",
      "reasoningTokenEnd": "\u003c/think\u003e",
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "true",
        "toolsBiased": "true",
        "toolCallRequired": true,
        "json": true,
        "jsonSchema": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      }
    },
    {
      "models": [
        "Qwen/Qwen3-235B-A22B-Thinking-2507"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "Qwen/Qwen3-235B-A22B-fp8-tput"
      ],
      "good": true,
      "in": {},
      "out": {}
    },
    {
      "comments": "TogetherAI has broken reasoning parsing during tool call and JSON output",
      "models": [
        "openai/gpt-oss-20b"
      ],
      "cheap": true,
      "reason": true,
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "flaky",
        "toolsBiased": "true",
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "tools": "flaky",
        "toolCallRequired": true,
        "topLogprobs": true
      }
    },
    {
      "models": [
        "openai/gpt-oss-20b"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "google/imagen-4.0-ultra"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "ByteDance-Seed/Seedream-3.0"
      ],
      "in": {},
      "out": {}
    },
    {
      "comments": "Tool calling is flaky because Together.AI only supports tool_choice auto, not required.",
      "models": [
        "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8"
      ],
      "in": {},
      "out": {}
    },
    {
      "comments": "FinishReason is only broken with JSON.",
      "models": [
        "mistralai/Mistral-Small-24B-Instruct-2501"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "black-forest-labs/FLUX.1-schnell-Free"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "black-forest-labs/FLUX.1-schnell"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "black-forest-labs/FLUX.1-dev"
      ],
      "in": {},
      "out": {}
    },
    {
      "comments": "Untested",
      "models": [
        "Alibaba-NLP/gte-modernbert-base",
        "Qwen/QwQ-32B",
        "Qwen/Qwen2.5-72B-Instruct-Turbo",
        "Qwen/Qwen2.5-7B-Instruct-Turbo",
        "Qwen/Qwen2.5-Coder-32B-Instruct",
        "Qwen/Qwen2.5-VL-72B-Instruct",
        "Salesforce/Llama-Rank-V1",
        "Virtue-AI/VirtueGuard-Text-Lite",
        "arcee-ai/AFM-4.5B",
        "arcee-ai/coder-large",
        "arcee-ai/maestro-reasoning",
        "arcee-ai/virtuoso-large",
        "arcee_ai/arcee-spotlight",
        "arize-ai/qwen-2-1.5b-instruct",
        "black-forest-labs/FLUX.1-dev-lora",
        "black-forest-labs/FLUX.1-kontext-dev",
        "black-forest-labs/FLUX.1-kontext-max",
        "black-forest-labs/FLUX.1-kontext-pro",
        "black-forest-labs/FLUX.1-krea-dev",
        "black-forest-labs/FLUX.1-pro",
        "black-forest-labs/FLUX.1.1-pro",
        "cartesia/sonic",
        "cartesia/sonic-2",
        "deepcogito/cogito-v2-preview-deepseek-671b",
        "deepcogito/cogito-v2-preview-llama-109B-MoE",
        "deepcogito/cogito-v2-preview-llama-405B",
        "deepcogito/cogito-v2-preview-llama-70B",
        "deepseek-ai/DeepSeek-R1",
        "deepseek-ai/DeepSeek-R1-0528-tput",
        "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
        "deepseek-ai/DeepSeek-V3",
        "google/gemma-3n-E4B-it",
        "intfloat/multilingual-e5-large-instruct",
        "lgai/exaone-3-5-32b-instruct",
        "lgai/exaone-deep-32b",
        "marin-community/marin-8b-instruct",
        "meta-llama/Llama-2-70b-hf",
        "meta-llama/Llama-3-70b-chat-hf",
        "meta-llama/Llama-3.2-3B-Instruct-Turbo",
        "meta-llama/Llama-3.3-70B-Instruct-Turbo",
        "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
        "meta-llama/Llama-Guard-3-11B-Vision-Turbo",
        "meta-llama/Llama-Guard-4-12B",
        "meta-llama/LlamaGuard-2-8b",
        "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3-8B-Instruct-Lite",
        "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "meta-llama/Meta-Llama-Guard-3-8B",
        "mistralai/Mistral-7B-Instruct-v0.1",
        "mistralai/Mistral-7B-Instruct-v0.3",
        "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "mixedbread-ai/Mxbai-Rerank-Large-V2",
        "openai/whisper-large-v3",
        "scb10x/scb10x-llama3-1-typhoon2-70b-instruct",
        "scb10x/scb10x-typhoon-2-1-gemma3-12b",
        "togethercomputer/MoA-1",
        "togethercomputer/MoA-1-Turbo",
        "togethercomputer/Refuel-Llm-V2",
        "togethercomputer/Refuel-Llm-V2-Small",
        "togethercomputer/m2-bert-80M-32k-retrieval",
        "zai-org/GLM-4.5-Air-FP8"
      ]
    },
    {
      "models": [
        "black-forest-labs/FLUX.2-flex"
      ],
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "image": {
          "url": true,
          "supportedFormats": [
            "image/jpeg"
          ]
        }
      },
      "GenSync": {
        "seed": true
      }
    },
    {
      "models": [
        "HiDream-ai/HiDream-I1-Full"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "Lykon/DreamShaper"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "HiDream-ai/HiDream-I1-Dev"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "Qwen/Qwen-Image"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "RunDiffusion/Juggernaut-pro-flux"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "google/imagen-4.0-preview"
      ],
      "in": {},
      "out": {}
    },
    {
      "comments": "TogetherAI has broken reasoning parsing during tool call and JSON output",
      "models": [
        "openai/gpt-oss-120b"
      ],
      "reason": true,
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "text": {
          "inline": true
        }
      },
      "GenSync": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "topLogprobs": true,
        "maxTokens": true,
        "stopSequence": true
      },
      "GenStream": {
        "reportRateLimits": true,
        "reportTokenUsage": "true",
        "reportFinishReason": "true",
        "seed": true,
        "topLogprobs": true
      }
    },
    {
      "models": [
        "stabilityai/stable-diffusion-3-medium"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "google/flash-image-2.5"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "HiDream-ai/HiDream-I1-Fast"
      ],
      "in": {},
      "out": {}
    },
    {
      "comments": "Tool calling is flaky because Together.AI only supports tool_choice auto, not required.",
      "models": [
        "meta-llama/Llama-4-Scout-17B-16E-Instruct"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "ByteDance-Seed/Seedream-4.0"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "ideogram/ideogram-3.0"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "openai/gpt-oss-120b"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "google/imagen-4.0-fast"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "Rundiffusion/Juggernaut-Lightning-Flux"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "stabilityai/stable-diffusion-xl-base-1.0"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "google/gemini-3-pro-image"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "black-forest-labs/FLUX.2-pro"
      ],
      "in": {
        "text": {
          "inline": true
        }
      },
      "out": {
        "image": {
          "url": true,
          "supportedFormats": [
            "image/jpeg"
          ]
        }
      },
      "GenSync": {
        "seed": true
      }
    },
    {
      "models": [
        "black-forest-labs/FLUX.2-dev"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "meta-llama/Llama-3.1-405B-Instruct"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "deepseek-ai/DeepSeek-V3.1"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "meta-llama/Meta-Llama-3.1-70B-Instruct-Reference"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "meta-llama/Llama-3.2-1B-Instruct"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "Qwen/Qwen2.5-14B-Instruct"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "meta-llama/Meta-Llama-3-8B-Instruct"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"
      ],
      "in": {},
      "out": {}
    },
    {
      "models": [
        "Qwen/Qwen2.5-72B-Instruct"
      ],
      "in": {},
      "out": {}
    }
  ]
}
